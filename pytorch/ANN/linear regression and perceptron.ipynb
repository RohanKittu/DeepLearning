{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating a class and object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.A object at 0x123fc9810>\n"
     ]
    }
   ],
   "source": [
    "class A():\n",
    "    pass\n",
    "c = A()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first parameter of the method must be refered as self ,self point to the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello welcome\n"
     ]
    }
   ],
   "source": [
    "class Ed():\n",
    "    def fu(self):\n",
    "        print(\"hello welcome\")\n",
    "d = Ed()\n",
    "d.fu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two type of class attributes present\n",
    "- user defined class attributes\n",
    "- in built class attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In build class attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__module__': '__main__', 'fu': <function Ed.fu at 0x123efeef0>, '__dict__': <attribute '__dict__' of 'Ed' objects>, '__weakref__': <attribute '__weakref__' of 'Ed' objects>, '__doc__': None}\n",
      "None\n",
      "The class name is :-  Ed\n",
      "the module name is :-  __main__\n",
      "This module gives the base class names : - <class 'object'>\n"
     ]
    }
   ],
   "source": [
    "print(Ed.__dict__)\n",
    "#it shows the class documentation\n",
    "print(Ed.__doc__)\n",
    "#This gives the class name\n",
    "print(\"The class name is :- \",Ed.__name__)\n",
    "#this gives the module name in which the class is defined\n",
    "print(\"the module name is :- \",Ed.__module__)\n",
    "#The belowe attribute tells about the base class\n",
    "print(\"This module gives the base class names : -\",Ed.__base__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user defined attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A():\n",
    "    def f():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some access specifier for the attributes\n",
    "- public\n",
    "- private\n",
    "- protected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The public variable is :-  hello i am public\n",
      "The protected variable is :-  hello i am protected\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'f' object has no attribute '__private'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0ab40d9c70e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The public variable is :- \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The protected variable is :- \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Thr private variable is :- \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__private\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'f' object has no attribute '__private'"
     ]
    }
   ],
   "source": [
    "class f:\n",
    "    def __init__(self):\n",
    "        self.public = (\"hello i am public\")\n",
    "        self._protected = (\"hello i am protected\")\n",
    "        self.__private = (\"I am private\")\n",
    "b = f()\n",
    "print(\"The public variable is :- \",b.public)\n",
    "print(\"The protected variable is :- \",b._protected)\n",
    "print(\"Thr private variable is :- \",b.__private)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : we can have public ,private and potected methods as wll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### class variable and instance variableB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "class G():\n",
    "    #class variable\n",
    "    name = \"hello\"\n",
    "    def some_name(self,name1):\n",
    "        #class variable\n",
    "        self.name1 = name1\n",
    "#instance variable\n",
    "obj = G()\n",
    "print(obj.name)\n",
    "obj.some_name(\"rohan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cconstructure and distructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructure is init\n",
      "destructing the object\n"
     ]
    }
   ],
   "source": [
    "class D():\n",
    "    def __init__(self):\n",
    "        print(\"constructure is init\")\n",
    "    def __del__(self):\n",
    "        print(\"destructing the object\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    b = D()\n",
    "    del b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple constructors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class D():\n",
    "    def __init__(self,name,roll_no,height,weight):\n",
    "        self.name = name\n",
    "        self.roll_no = roll_no\n",
    "        self.height = height\n",
    "        self.weight = weight\n",
    "    @classmethod\n",
    "    def r(self,roll_no,height,weight,name):\n",
    "        self.name = name\n",
    "        self.roll_no = roll_no\n",
    "        self.height = height                         \n",
    "        self.weight = weight\n",
    "v = D(\"rohan\",23,45,67)\n",
    "v.roll_no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inheretance\n",
    "single ingeretance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello i am a base class\n"
     ]
    }
   ],
   "source": [
    "class base():\n",
    "    def fu(self):\n",
    "        print(\"hello i am a base class\")\n",
    "class child(base):\n",
    "    def f(self):\n",
    "        print(\"hello i am a child class\")\n",
    "c = child()\n",
    "c.fu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multiple inheretance and super keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class base:\n",
    "    def __init__(self,name):\n",
    "        self.name = name\n",
    "    pass\n",
    "class ch(base):\n",
    "    def __init__(self,name):\n",
    "        super(). __init__(name)\n",
    "obj = ch(\"hello\")\n",
    "obj.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating the data for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# create dummy data for training\n",
    "\n",
    "#creating the x_values\n",
    "x_values = [i for i in range(11)]\n",
    "#making the list to array\n",
    "x_train = np.array(x_values, dtype=np.float32)\n",
    "#reshaping the array\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "\n",
    "\n",
    "#creating the y_values \n",
    "y_values = [2*i + 1 for i in x_values]\n",
    "y_train = np.array(y_values, dtype=np.float32)\n",
    "y_train = y_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 4.],\n",
       "       [ 5.],\n",
       "       [ 6.],\n",
       "       [ 7.],\n",
       "       [ 8.],\n",
       "       [ 9.],\n",
       "       [10.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 7.],\n",
       "       [ 9.],\n",
       "       [11.],\n",
       "       [13.],\n",
       "       [15.],\n",
       "       [17.],\n",
       "       [19.],\n",
       "       [21.]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating the linear regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "class linearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(linearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "down below we are creating the neural network,where inputDim tells the number of input bubbles in the input layer,outputDim tells the number of output bubbles in the output layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDim = 1        # takes variable 'x' \n",
    "outputDim = 1       # takes variable 'y'\n",
    "learningRate = 0.01 \n",
    "epochs = 100\n",
    "\n",
    "#now the network is build.\n",
    "model = linearRegression(inputDim, outputDim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we are passing the data into neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we initialize the loss (Mean Squared Error) and optimization (Stochastic Gradient Descent) functions that we’ll use in the training of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing all the initializations, we can now begin to train our model. Following is the code for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(71.2547, grad_fn=<MseLossBackward>)\n",
      "epoch 0, loss 71.25465393066406\n",
      "tensor(5.8120, grad_fn=<MseLossBackward>)\n",
      "epoch 1, loss 5.812027454376221\n",
      "tensor(0.4741, grad_fn=<MseLossBackward>)\n",
      "epoch 2, loss 0.47407886385917664\n",
      "tensor(0.0387, grad_fn=<MseLossBackward>)\n",
      "epoch 3, loss 0.038679301738739014\n",
      "tensor(0.0032, grad_fn=<MseLossBackward>)\n",
      "epoch 4, loss 0.003164922120049596\n",
      "tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "epoch 5, loss 0.00026798731414601207\n",
      "tensor(3.1604e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 6, loss 3.16039877361618e-05\n",
      "tensor(1.2216e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 7, loss 1.221599814016372e-05\n",
      "tensor(1.0526e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 8, loss 1.052606512530474e-05\n",
      "tensor(1.0283e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 9, loss 1.0282961738994345e-05\n",
      "tensor(1.0157e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 10, loss 1.0157100405194797e-05\n",
      "tensor(1.0043e-05, grad_fn=<MseLossBackward>)\n",
      "epoch 11, loss 1.0042811481980607e-05\n",
      "tensor(9.9299e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 12, loss 9.929900443239603e-06\n",
      "tensor(9.8197e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 13, loss 9.819716069614515e-06\n",
      "tensor(9.7093e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 14, loss 9.70930796029279e-06\n",
      "tensor(9.6011e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 15, loss 9.601079000276513e-06\n",
      "tensor(9.4936e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 16, loss 9.49355944612762e-06\n",
      "tensor(9.3881e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 17, loss 9.388105354446452e-06\n",
      "tensor(9.2838e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 18, loss 9.283784493163694e-06\n",
      "tensor(9.1790e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 19, loss 9.178969776257873e-06\n",
      "tensor(9.0775e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 20, loss 9.07753474166384e-06\n",
      "tensor(8.9759e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 21, loss 8.975855962489732e-06\n",
      "tensor(8.8754e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 22, loss 8.875383173290174e-06\n",
      "tensor(8.7770e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 23, loss 8.77704587765038e-06\n",
      "tensor(8.6781e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 24, loss 8.678107406012714e-06\n",
      "tensor(8.5814e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 25, loss 8.581354450143408e-06\n",
      "tensor(8.4853e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 26, loss 8.485312719130889e-06\n",
      "tensor(8.3900e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 27, loss 8.390047696593683e-06\n",
      "tensor(8.2970e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 28, loss 8.297034582938068e-06\n",
      "tensor(8.2039e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 29, loss 8.203925062844064e-06\n",
      "tensor(8.1129e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 30, loss 8.112920113489963e-06\n",
      "tensor(8.0215e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 31, loss 8.021450412343256e-06\n",
      "tensor(7.9326e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 32, loss 7.932632797746919e-06\n",
      "tensor(7.8436e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 33, loss 7.843594175938051e-06\n",
      "tensor(7.7571e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 34, loss 7.75706212152727e-06\n",
      "tensor(7.6691e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 35, loss 7.66905395721551e-06\n",
      "tensor(7.5839e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 36, loss 7.583902970509371e-06\n",
      "tensor(7.4992e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 37, loss 7.49924402043689e-06\n",
      "tensor(7.4148e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 38, loss 7.41480562282959e-06\n",
      "tensor(7.3321e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 39, loss 7.332109362323536e-06\n",
      "tensor(7.2509e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 40, loss 7.2508860284870025e-06\n",
      "tensor(7.1696e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 41, loss 7.169585387600819e-06\n",
      "tensor(7.0903e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 42, loss 7.09031883161515e-06\n",
      "tensor(7.0104e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 43, loss 7.0104347287269775e-06\n",
      "tensor(6.9334e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 44, loss 6.93341053192853e-06\n",
      "tensor(6.8551e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 45, loss 6.8550525611499324e-06\n",
      "tensor(6.7796e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 46, loss 6.779603609174956e-06\n",
      "tensor(6.7027e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 47, loss 6.702655809931457e-06\n",
      "tensor(6.6279e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 48, loss 6.627881248277845e-06\n",
      "tensor(6.5537e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 49, loss 6.553681942023104e-06\n",
      "tensor(6.4805e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 50, loss 6.480532192654209e-06\n",
      "tensor(6.4083e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 51, loss 6.40829830445e-06\n",
      "tensor(6.3369e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 52, loss 6.336919341265457e-06\n",
      "tensor(6.2659e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 53, loss 6.265920092118904e-06\n",
      "tensor(6.1966e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 54, loss 6.1966097746335436e-06\n",
      "tensor(6.1263e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 55, loss 6.126254447735846e-06\n",
      "tensor(6.0583e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 56, loss 6.0583142840187065e-06\n",
      "tensor(5.9900e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 57, loss 5.989951205265243e-06\n",
      "tensor(5.9243e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 58, loss 5.924293418502202e-06\n",
      "tensor(5.8576e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 59, loss 5.85756242799107e-06\n",
      "tensor(5.7933e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 60, loss 5.7932543313654605e-06\n",
      "tensor(5.7277e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 61, loss 5.72771978113451e-06\n",
      "tensor(5.6632e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 62, loss 5.663214778905967e-06\n",
      "tensor(5.6000e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 63, loss 5.600032636721153e-06\n",
      "tensor(5.5379e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 64, loss 5.5379155128321145e-06\n",
      "tensor(5.4756e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 65, loss 5.475633770402055e-06\n",
      "tensor(5.4151e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 66, loss 5.415090072347084e-06\n",
      "tensor(5.3555e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 67, loss 5.35545268576243e-06\n",
      "tensor(5.2945e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 68, loss 5.29454064235324e-06\n",
      "tensor(5.2352e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 69, loss 5.235188382357592e-06\n",
      "tensor(5.1764e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 70, loss 5.176449121790938e-06\n",
      "tensor(5.1191e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 71, loss 5.11910275236005e-06\n",
      "tensor(5.0619e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 72, loss 5.061922365712235e-06\n",
      "tensor(5.0061e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 73, loss 5.00607575304457e-06\n",
      "tensor(4.9494e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 74, loss 4.949362846673466e-06\n",
      "tensor(4.8941e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 75, loss 4.8940846681944095e-06\n",
      "tensor(4.8396e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 76, loss 4.839644589083036e-06\n",
      "tensor(4.7851e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 77, loss 4.785089004144538e-06\n",
      "tensor(4.7314e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 78, loss 4.731383342004847e-06\n",
      "tensor(4.6793e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 79, loss 4.679347966884961e-06\n",
      "tensor(4.6276e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 80, loss 4.627625912689837e-06\n",
      "tensor(4.5755e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 81, loss 4.57552323496202e-06\n",
      "tensor(4.5246e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 82, loss 4.524568794295192e-06\n",
      "tensor(4.4737e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 83, loss 4.4736743802786805e-06\n",
      "tensor(4.4239e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 84, loss 4.423921382112894e-06\n",
      "tensor(4.3753e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 85, loss 4.375332537165377e-06\n",
      "tensor(4.3261e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 86, loss 4.326142061472638e-06\n",
      "tensor(4.2778e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 87, loss 4.27780423706281e-06\n",
      "tensor(4.2294e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 88, loss 4.229449132253649e-06\n",
      "tensor(4.1828e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 89, loss 4.182820703135803e-06\n",
      "tensor(4.1349e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 90, loss 4.134926712140441e-06\n",
      "tensor(4.0903e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 91, loss 4.0902973523770925e-06\n",
      "tensor(4.0446e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 92, loss 4.044582055939827e-06\n",
      "tensor(3.9996e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 93, loss 3.9996207306103315e-06\n",
      "tensor(3.9551e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 94, loss 3.955125066568144e-06\n",
      "tensor(3.9106e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 95, loss 3.910585746780271e-06\n",
      "tensor(3.8661e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 96, loss 3.866130100504961e-06\n",
      "tensor(3.8226e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 97, loss 3.822608505288372e-06\n",
      "tensor(3.7805e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 98, loss 3.780543465836672e-06\n",
      "tensor(3.7386e-06, grad_fn=<MseLossBackward>)\n",
      "epoch 99, loss 3.7386337226053e-06\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # Converting inputs and labels to Variable\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = Variable(torch.from_numpy(x_train).cuda())\n",
    "        labels = Variable(torch.from_numpy(y_train).cuda())\n",
    "    else:\n",
    "        inputs = Variable(torch.from_numpy(x_train))\n",
    "        labels = Variable(torch.from_numpy(y_train))\n",
    "\n",
    "    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # get output from the model, given the inputs\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # get loss for the predicted output\n",
    "    loss = criterion(outputs, labels)\n",
    "    print(loss)\n",
    "    # get gradients w.r.t to parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our Linear Regression Model is trained, let’s test it. Since it’s a very trivial model, we’ll test this on our existing dataset and also plot to see the original vs the predicted outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99640334]\n",
      " [ 2.9969215 ]\n",
      " [ 4.9974394 ]\n",
      " [ 6.9979577 ]\n",
      " [ 8.998476  ]\n",
      " [10.998994  ]\n",
      " [12.999513  ]\n",
      " [15.0000305 ]\n",
      " [17.000547  ]\n",
      " [19.001066  ]\n",
      " [21.001583  ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "with torch.no_grad(): # we don't need gradients in the testing phase\n",
    "    if torch.cuda.is_available():\n",
    "        predicted = model(Variable(torch.from_numpy(x_train).cuda())).cpu().data.numpy()\n",
    "    else:\n",
    "        predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
    "    print(predicted)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(x_train, y_train, 'go', label='True data', alpha=0.5)\n",
    "plt.plot(x_train, predicted, '--', label='Predictions', alpha=0.5)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12,  3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([12,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([[1,2,3],[4,56,6]])\n",
    "y=torch.tensor([[78,89,45],[90,89,54]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appling ANN on the vector data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note :- If we have the regression problem ,then we should not apply activation function,if its a classification problem ,then we apply activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preperation and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# create dummy data for training\n",
    "\n",
    "#creating the x_values\n",
    "x_values = [i for i in range(11)]\n",
    "#making the list to array\n",
    "x_train = np.array(x_values, dtype=np.float32)\n",
    "#reshaping the array\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "\n",
    "\n",
    "#creating the y_values \n",
    "y_values = [2*i + 1 for i in x_values]\n",
    "y_train = np.array(y_values, dtype=np.float32)\n",
    "y_train = y_train.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 3.],\n",
       "       [ 5.],\n",
       "       [ 7.],\n",
       "       [ 9.],\n",
       "       [11.],\n",
       "       [13.],\n",
       "       [15.],\n",
       "       [17.],\n",
       "       [19.],\n",
       "       [21.]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.1'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the neural network frame work.\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "class linearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(linearRegression, self).__init__()\n",
    "        self.layer1 = torch.nn.Linear(inputSize, outputSize)\n",
    "        self.layer2 = torch.nn.Linear(outputSize,outputSize)\n",
    "    def forward(self, x):\n",
    "        layer1_output = self.layer1(x)\n",
    "        layer2_output = self.layer2(layer1_output)\n",
    "        return layer2_output\n",
    "        #return layer1_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linearRegression(\n",
      "  (layer1): Linear(in_features=1, out_features=1, bias=True)\n",
      "  (layer2): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#initilizing the neural network\n",
    "brain = linearRegression(1,1)\n",
    "print(brain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#few parameter for the running the model.\n",
    "learning_rate = 0.01\n",
    "epoch = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3) Optimizer and Loss\n",
    "Next, you should define the Optimizer and the Loss Function for our training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Optimizer and Loss Function\n",
    "optimizer = torch.optim.SGD(brain.parameters(), lr=learning_rate)\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4) Training\n",
    "\n",
    "Now let's start our training process. With an epoch of 250, you will iterate our data to find the best value for our hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Variable(torch.from_numpy(x_train),requires_grad=True)\n",
    "y=Variable(torch.from_numpy(y_train),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 191.08831787109375 \n",
      "epoch 1, loss 164.63526916503906 \n",
      "epoch 2, loss 143.23992919921875 \n",
      "epoch 3, loss 100.6243667602539 \n",
      "epoch 4, loss 5.407934665679932 \n",
      "epoch 5, loss 13.742831230163574 \n",
      "epoch 6, loss 49.32242202758789 \n",
      "epoch 7, loss 21.271541595458984 \n",
      "epoch 8, loss 72.41836547851562 \n",
      "epoch 9, loss 3.354529619216919 \n",
      "epoch 10, loss 11.646188735961914 \n",
      "epoch 11, loss 23.058122634887695 \n",
      "epoch 12, loss 76.505859375 \n",
      "epoch 13, loss 1.1328445672988892 \n",
      "epoch 14, loss 3.462801218032837 \n",
      "epoch 15, loss 8.815278053283691 \n",
      "epoch 16, loss 30.903596878051758 \n",
      "epoch 17, loss 28.78058433532715 \n",
      "epoch 18, loss 89.86408233642578 \n",
      "epoch 19, loss 2.5055577754974365 \n",
      "epoch 20, loss 6.2965779304504395 \n",
      "epoch 21, loss 21.4255313873291 \n",
      "epoch 22, loss 27.55689239501953 \n",
      "epoch 23, loss 85.34708404541016 \n",
      "epoch 24, loss 1.3304615020751953 \n",
      "epoch 25, loss 3.230889320373535 \n",
      "epoch 26, loss 10.352380752563477 \n",
      "epoch 27, loss 19.28655242919922 \n",
      "epoch 28, loss 62.331912994384766 \n",
      "epoch 29, loss 5.276963710784912 \n",
      "epoch 30, loss 17.193443298339844 \n",
      "epoch 31, loss 24.239904403686523 \n",
      "epoch 32, loss 74.96198272705078 \n",
      "epoch 33, loss 0.3302537500858307 \n",
      "epoch 34, loss 0.43850472569465637 \n",
      "epoch 35, loss 0.7531003952026367 \n",
      "epoch 36, loss 1.8057599067687988 \n",
      "epoch 37, loss 4.265417575836182 \n",
      "epoch 38, loss 13.566475868225098 \n",
      "epoch 39, loss 21.38538360595703 \n",
      "epoch 40, loss 66.72557830810547 \n",
      "epoch 41, loss 2.008202075958252 \n",
      "epoch 42, loss 5.83430290222168 \n",
      "epoch 43, loss 11.995187759399414 \n",
      "epoch 44, loss 38.61623764038086 \n",
      "epoch 45, loss 18.643972396850586 \n",
      "epoch 46, loss 58.134498596191406 \n",
      "epoch 47, loss 5.401047229766846 \n",
      "epoch 48, loss 16.808263778686523 \n",
      "epoch 49, loss 21.880096435546875 \n",
      "epoch 50, loss 66.21234130859375 \n",
      "epoch 51, loss 1.3216087818145752 \n",
      "epoch 52, loss 3.399843692779541 \n",
      "epoch 53, loss 7.245536804199219 \n",
      "epoch 54, loss 22.541196823120117 \n",
      "epoch 55, loss 22.265295028686523 \n",
      "epoch 56, loss 66.38213348388672 \n",
      "epoch 57, loss 0.962916910648346 \n",
      "epoch 58, loss 2.2339913845062256 \n",
      "epoch 59, loss 4.798151016235352 \n",
      "epoch 60, loss 14.401131629943848 \n",
      "epoch 61, loss 19.510133743286133 \n",
      "epoch 62, loss 58.477928161621094 \n",
      "epoch 63, loss 3.4535605907440186 \n",
      "epoch 64, loss 9.941794395446777 \n",
      "epoch 65, loss 15.787604331970215 \n",
      "epoch 66, loss 47.64862060546875 \n",
      "epoch 67, loss 9.044597625732422 \n",
      "epoch 68, loss 27.314735412597656 \n",
      "epoch 69, loss 19.448476791381836 \n",
      "epoch 70, loss 57.0872917175293 \n",
      "epoch 71, loss 3.2103240489959717 \n",
      "epoch 72, loss 8.907797813415527 \n",
      "epoch 73, loss 14.136614799499512 \n",
      "epoch 74, loss 41.97481918334961 \n",
      "epoch 75, loss 11.255400657653809 \n",
      "epoch 76, loss 33.325828552246094 \n",
      "epoch 77, loss 15.728812217712402 \n",
      "epoch 78, loss 45.936763763427734 \n",
      "epoch 79, loss 8.169211387634277 \n",
      "epoch 80, loss 23.726167678833008 \n",
      "epoch 81, loss 18.31281852722168 \n",
      "epoch 82, loss 52.40293884277344 \n",
      "epoch 83, loss 4.115437984466553 \n",
      "epoch 84, loss 11.257697105407715 \n",
      "epoch 85, loss 15.157891273498535 \n",
      "epoch 86, loss 43.48789596557617 \n",
      "epoch 87, loss 8.516725540161133 \n",
      "epoch 88, loss 24.258649826049805 \n",
      "epoch 89, loss 17.14917755126953 \n",
      "epoch 90, loss 48.393009185791016 \n",
      "epoch 91, loss 5.289402484893799 \n",
      "epoch 92, loss 14.473093032836914 \n",
      "epoch 93, loss 16.14641761779785 \n",
      "epoch 94, loss 45.321533203125 \n",
      "epoch 95, loss 6.497049331665039 \n",
      "epoch 96, loss 17.871686935424805 \n",
      "epoch 97, loss 16.56981658935547 \n",
      "epoch 98, loss 46.033329010009766 \n",
      "epoch 99, loss 5.68945837020874 \n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    prediction = brain(x)\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_func(prediction,y)\n",
    "    loss.backward()        \n",
    "    optimizer.step()\n",
    "    print('epoch {}, loss {} '.format(i, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.1179],\n",
       "        [ 3.3038],\n",
       "        [ 4.4897],\n",
       "        [ 5.6756],\n",
       "        [ 6.8615],\n",
       "        [ 8.0474],\n",
       "        [ 9.2332],\n",
       "        [10.4191],\n",
       "        [11.6050],\n",
       "        [12.7909],\n",
       "        [13.9768]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=brain(x)\n",
    "pre=pre.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error is :-  3.9173980327644693\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "rms = sqrt(mean_squared_error(y.detach().numpy(),pre))\n",
    "print(\"The error is :- \",rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.plot(x_train, y_train, 'go', label='True data', alpha=0.5)\n",
    "plt.plot(x_train, pre, '--', label='Predictions', alpha=0.5)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting a new value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.2523]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain(Variable(torch.tensor([[float(5)]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([i for i in range(0,12)],dtype = np.float32)\n",
    "y_train = np.array([0,1,0,1,0,1,0,1,0,1,0,1],dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 1)\n",
    "y_train = y_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the structure of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self,inputSize, outputSize):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        #As logistic regression use sigmoid function,so we are using sigmoid as our activation function.\n",
    "        output = self.linear(x)\n",
    "        output = self.relu(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating the model of the above neural network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#few parameter for the running the model.\n",
    "learning_rate = 0.01\n",
    "epoch = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the loss function, we use Binary Cross-Entropy (BCE), which is known as the binary logarithmic loss function. This is commonly used for logistic regression tasks since we are predicting a binary value as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# Define Optimizer and Loss Function\n",
    "optimizer = torch.optim.SGD(brain.parameters(), lr=learning_rate)\n",
    "#loss_func = torch.nn.MSELoss() for regression\n",
    "loss_func = torch.nn.BCELoss(size_average=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Variable(torch.from_numpy(x_train),requires_grad=True)\n",
    "y=Variable(torch.from_numpy(y_train),requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([12, 1])) that is different to the input size (torch.Size([12, 2])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target and input must have the same number of elements. target nelement (12) != input nelement (24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-6322201c4da4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2056\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2057\u001b[0m         raise ValueError(\"Target and input must have the same number of elements. target nelement ({}) \"\n\u001b[0;32m-> 2058\u001b[0;31m                          \"!= input nelement ({})\".format(target.numel(), input.numel()))\n\u001b[0m\u001b[1;32m   2059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target and input must have the same number of elements. target nelement (12) != input nelement (24)"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    model.train()\n",
    "    prediction = model(x)\n",
    "    optimizer.zero_grad()\n",
    "    print(len(prediction))\n",
    "    print(len(y))\n",
    "    loss = loss_func(prediction,y)\n",
    "    loss.backward()        \n",
    "    optimizer.step()\n",
    "    print('epoch {}, loss {} '.format(i, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9995, 0.2075],\n",
       "        [0.9062, 0.2807],\n",
       "        [0.8128, 0.3540],\n",
       "        [0.7195, 0.4272],\n",
       "        [0.6261, 0.5005],\n",
       "        [0.5328, 0.5737],\n",
       "        [0.4395, 0.6470],\n",
       "        [0.3461, 0.7202],\n",
       "        [0.2528, 0.7935],\n",
       "        [0.1594, 0.8667],\n",
       "        [0.0661, 0.9400],\n",
       "        [0.0000, 1.0132]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually building weights and biases\n",
    "One way to approach this is by building all the blocks. This is a low level approach, but it may be suited if you’re trying to reproduce the latest and greatest deep learning architecture on a paper you just just read. Or maybe if you want to develop a customized layer. Either way, PyTorch has you covered. You’ll need to define your weights and biases, but if you’re comfortable at that level, you’re good to go. The key thing here is that you will need to tell PyTorch what is variable or optimizable in your network, so that PyTorch knows how to perform gradient descent on your network. Let’s look at how someone might approach this in low level PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# generating some random features\n",
    "features = torch.randn(1, 16) \n",
    "\n",
    "# define the weights\n",
    "W1 = torch.randn((16, 12), requires_grad=True)\n",
    "W2 = torch.randn((12, 10), requires_grad=True)\n",
    "W3 = torch.randn((10, 1), requires_grad=True)\n",
    "\n",
    "# define the bias terms\n",
    "B1 = torch.randn((12), requires_grad=True)\n",
    "B2 = torch.randn((10), requires_grad=True)\n",
    "B3 = torch.randn((1), requires_grad=True)\n",
    "\n",
    "# calculate hidden and output layers\n",
    "h1 = F.relu((features @ W1) + B1)\n",
    "h2 = F.relu((h1 @ W2) + B2)\n",
    "output = torch.sigmoid((h2 @ W3) + B3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extending the torch.nn.Model Class\n",
    "In practice, most of us will likely use predefined layers and activation functions to train our networks. There are a couple of routes to go if you’re headed in this direction. A more elegant approach involves creating your own neural network python class, by extending the Model class from torch.nn. There are many advantages of defining a neural network this way and perhaps most notably, it allows one to inherit all of the functionality of the torch.nn module while allowing the flexibility of overwriting the default model construction and forward pass method. In this approach, we will define two methods:\n",
    "1. The class constructor, __init__\n",
    "2. The forward method\n",
    "The first is the initializer of the class and is where you’ll define the layers that will compose the network. Typically we don’t need to define the activation functions here since they can be defined in the forward pass (i.e. in the forward method), but it’s not a rule and you can certainly do that if you want to (we’ll actually see an example at the end).\n",
    "The second method is where you define the forward pass. This method takes an input that represents the features the model will be trained on. Here, you can call the activation functions and pass in as parameters the layers you’ve previously defined in the constructor method. You’ll need to pass the input as an argument to the first layer and after processing the activations, that output can be fed into the next layer and so on.\n",
    "Let’s take a look at how we could do this in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNetwork(\n",
      "  (fc1): Linear(in_features=16, out_features=12, bias=True)\n",
      "  (fc2): Linear(in_features=12, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "# define the network class\n",
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        # call constructor from superclass\n",
    "        super().__init__()\n",
    "        \n",
    "        # define network layers\n",
    "        self.fc1 = nn.Linear(16, 12)\n",
    "        self.fc2 = nn.Linear(12, 10)\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # define forward pass\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# instantiate the model\n",
    "model = MyNetwork()\n",
    "\n",
    "# print model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Using torch.nn.Sequential\n",
    "There is still a more compact way to define neural networks in pytorch. This is a modular approach, made possible by the torch.nn.Sequential module and is especially appealing if you come from a Keras background, where you can define sequential layers, kind of like building something from lego blocks. This is a very similar approach to Keras’s sequential API and leverages the torch.nn pre-built layers and activation functions. Using this approach, our feed-forward network can be defined a follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=16, out_features=12, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=12, out_features=10, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=10, out_features=1, bias=True)\n",
      "  (5): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "# define model architecture\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(16, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# print model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classificatio using pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "X,y = sklearn.datasets.make_moons(200,noise=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn' has no attribute 'cm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-665cf8e0f3ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpectral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn' has no attribute 'cm'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X[:,0],X[:,1],s=40,c=y,cmap=sklearn.cm.Spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.13058442e-01,  1.10641925e+00],\n",
       "       [-7.08581418e-02,  1.69772315e-01],\n",
       "       [-7.64997815e-01,  7.88383860e-01],\n",
       "       [ 1.11504116e+00, -3.27555480e-01],\n",
       "       [ 2.46041384e+00,  4.50351154e-01],\n",
       "       [ 8.46794340e-01, -2.15436616e-01],\n",
       "       [-7.35038371e-01,  8.79679171e-01],\n",
       "       [-8.61805652e-02, -1.66946993e-01],\n",
       "       [ 1.01624539e+00, -6.06422487e-01],\n",
       "       [ 8.86666461e-01, -6.92366549e-01],\n",
       "       [ 9.90044589e-01,  1.38344594e-01],\n",
       "       [ 9.08846127e-01,  7.05377758e-04],\n",
       "       [ 1.56276768e-01, -1.01039877e-01],\n",
       "       [-9.03625464e-01,  8.21981959e-01],\n",
       "       [ 1.24091509e+00, -5.24642004e-01],\n",
       "       [-2.37075800e-01,  9.42723311e-01],\n",
       "       [ 4.30767357e-01,  3.77067770e-01],\n",
       "       [ 8.31677130e-01,  9.74791131e-01],\n",
       "       [ 8.13628618e-01,  6.34571158e-01],\n",
       "       [ 3.76607281e-01, -6.22223463e-02],\n",
       "       [-1.17927181e+00,  3.73646205e-01],\n",
       "       [ 1.70091991e+00,  6.17004762e-02],\n",
       "       [-1.00288259e+00,  6.17964701e-01],\n",
       "       [ 1.59818165e+00, -3.02162888e-01],\n",
       "       [ 2.96184685e-02,  1.02644198e+00],\n",
       "       [ 2.73932893e-01,  1.13871527e+00],\n",
       "       [ 9.43719220e-03,  9.79565919e-01],\n",
       "       [ 8.35221216e-01, -4.24993698e-01],\n",
       "       [-1.26493847e+00, -9.90702488e-02],\n",
       "       [ 1.22191712e+00, -6.47043977e-01],\n",
       "       [ 9.64945306e-01,  5.82997539e-01],\n",
       "       [ 1.32833188e+00, -1.23413961e-01],\n",
       "       [ 5.53598273e-01,  7.68730643e-01],\n",
       "       [ 2.60415597e-02,  9.22826448e-02],\n",
       "       [ 1.68213650e+00, -2.81223196e-01],\n",
       "       [ 6.30619745e-01, -9.90902021e-02],\n",
       "       [ 1.06826343e+00,  2.81581729e-02],\n",
       "       [-3.32326654e-01,  1.02699398e+00],\n",
       "       [ 6.00422339e-01,  7.95658403e-01],\n",
       "       [-5.28071467e-01,  5.60770670e-01],\n",
       "       [-5.05613053e-01,  4.59501496e-01],\n",
       "       [-9.46345839e-01,  5.35566492e-01],\n",
       "       [-9.87074216e-01,  5.71739709e-02],\n",
       "       [ 4.90888202e-01, -9.49646778e-02],\n",
       "       [ 5.74544127e-01, -5.77881501e-01],\n",
       "       [-1.12920399e-01,  3.70524939e-01],\n",
       "       [ 3.77247179e-01,  1.04585872e+00],\n",
       "       [ 4.89369192e-01, -4.88966394e-01],\n",
       "       [ 7.86041219e-01,  5.07480756e-01],\n",
       "       [ 2.10023485e-01,  1.06634299e+00],\n",
       "       [ 6.21610628e-01, -3.72975035e-01],\n",
       "       [ 1.84701812e+00,  1.24564889e-01],\n",
       "       [ 1.62469656e+00, -4.40262276e-01],\n",
       "       [-8.74590555e-02, -1.36299684e-01],\n",
       "       [ 8.52632194e-01, -3.25669957e-01],\n",
       "       [ 1.84906945e+00,  9.67304951e-02],\n",
       "       [ 1.11185701e+00, -9.39020943e-01],\n",
       "       [ 1.11827903e+00,  6.88538473e-01],\n",
       "       [ 9.62342960e-01,  2.04522988e-01],\n",
       "       [ 6.06009677e-01,  7.70506865e-01],\n",
       "       [ 8.29275278e-01, -7.13761002e-01],\n",
       "       [ 1.73300219e-01, -3.19025183e-01],\n",
       "       [-9.77714967e-01,  1.07345306e-01],\n",
       "       [ 2.01032177e+00, -2.80799189e-01],\n",
       "       [-1.18706675e+00,  6.51621173e-01],\n",
       "       [-5.15038390e-01,  1.09615436e+00],\n",
       "       [-9.36889347e-01,  2.81336426e-01],\n",
       "       [ 2.10732290e+00,  6.33935518e-01],\n",
       "       [ 1.29229290e+00, -3.59161809e-01],\n",
       "       [ 5.14338245e-01,  6.17000590e-01],\n",
       "       [-1.25929115e+00,  7.40178097e-02],\n",
       "       [ 8.72128223e-01, -1.08017863e-01],\n",
       "       [ 5.80764917e-01,  7.22864337e-01],\n",
       "       [ 7.77490026e-01, -6.40182930e-01],\n",
       "       [ 3.72622195e-01,  8.55518007e-01],\n",
       "       [ 2.00545127e-01,  7.08706738e-01],\n",
       "       [-2.98044732e-01,  9.94748920e-01],\n",
       "       [ 4.15163311e-01, -3.16095907e-01],\n",
       "       [ 1.96059454e+00, -4.66488311e-02],\n",
       "       [ 6.63285014e-01, -3.34905521e-01],\n",
       "       [ 2.20288390e+00,  3.59011742e-01],\n",
       "       [-7.56542046e-01,  9.71909389e-02],\n",
       "       [ 9.03126821e-01,  1.42924490e-01],\n",
       "       [ 3.84761124e-01, -4.82506025e-01],\n",
       "       [ 4.28203728e-01, -5.23876673e-01],\n",
       "       [ 1.63590012e+00, -4.00860771e-02],\n",
       "       [-1.76335808e-02,  1.17916212e+00],\n",
       "       [ 1.64488656e+00, -3.08011501e-01],\n",
       "       [-1.80492981e-01,  6.68741567e-01],\n",
       "       [ 1.05712348e+00,  2.12853942e-01],\n",
       "       [ 3.74615384e-01, -1.56465554e-01],\n",
       "       [ 9.26671246e-02,  1.02245843e+00],\n",
       "       [-1.17761561e+00,  2.06851816e-01],\n",
       "       [-4.48490768e-01,  1.12911068e+00],\n",
       "       [ 9.79487066e-01,  5.03497704e-01],\n",
       "       [-4.92835224e-02,  1.51254548e-01],\n",
       "       [ 2.05341174e+00,  1.86923834e-01],\n",
       "       [ 1.66324399e+00,  5.32855531e-02],\n",
       "       [-1.56154502e-02,  1.12590861e+00],\n",
       "       [ 6.17735967e-01, -1.58513285e-01],\n",
       "       [ 1.46179375e-01, -3.41683912e-01],\n",
       "       [-5.64365063e-01,  8.93732922e-01],\n",
       "       [-9.87649416e-01,  3.69642657e-01],\n",
       "       [-1.00319053e+00,  3.56459560e-01],\n",
       "       [ 1.17068253e+00, -4.92465056e-01],\n",
       "       [ 2.35194721e-01,  1.95299279e-02],\n",
       "       [-3.40649167e-02,  1.08535123e+00],\n",
       "       [ 1.82984546e-01,  1.41787222e-01],\n",
       "       [ 2.16864470e+00,  3.31572218e-02],\n",
       "       [-8.42364800e-01,  1.25295782e+00],\n",
       "       [-1.80800191e-01,  5.95102900e-01],\n",
       "       [ 3.33873761e-01, -3.40783971e-01],\n",
       "       [ 1.42073746e+00, -1.55926015e-01],\n",
       "       [ 1.65420860e+00,  3.03873904e-02],\n",
       "       [ 5.53157495e-01,  5.49825949e-01],\n",
       "       [ 1.55551772e+00, -1.77717232e-02],\n",
       "       [ 2.03760128e+00,  5.09047469e-01],\n",
       "       [-1.50465947e-02,  3.24163315e-02],\n",
       "       [ 3.73108172e-01,  6.05653022e-01],\n",
       "       [ 6.88302522e-01,  7.91190068e-01],\n",
       "       [ 2.24770332e+00,  2.68048567e-01],\n",
       "       [ 1.76165743e+00,  6.41143501e-03],\n",
       "       [ 1.57724883e-01,  5.00032107e-02],\n",
       "       [ 4.77331002e-01, -4.23504529e-01],\n",
       "       [ 1.51097710e+00, -4.05977605e-01],\n",
       "       [-7.81529165e-01,  2.72938103e-01],\n",
       "       [ 6.27530142e-01, -2.39840164e-01],\n",
       "       [ 2.60525297e-01, -8.68204822e-02],\n",
       "       [ 1.12943970e+00, -2.46448817e-01],\n",
       "       [ 1.10807855e+00,  1.95100168e-01],\n",
       "       [ 2.60945060e-01, -1.41343144e-01],\n",
       "       [-6.86830080e-01,  1.27805242e+00],\n",
       "       [ 9.12635704e-02,  9.24692548e-01],\n",
       "       [ 1.59914302e+00, -4.63659862e-01],\n",
       "       [ 7.52095686e-01,  9.36942892e-01],\n",
       "       [ 2.78077072e-01,  1.24571692e+00],\n",
       "       [ 1.12221598e+00, -2.72954693e-01],\n",
       "       [ 8.17456888e-01,  5.40988063e-01],\n",
       "       [ 8.34031556e-01,  1.37910438e-01],\n",
       "       [-4.79835016e-01,  1.18857279e+00],\n",
       "       [ 8.60767513e-01,  5.15200634e-01],\n",
       "       [-9.70105835e-01,  3.43128806e-01],\n",
       "       [ 9.27620256e-02,  4.21458068e-01],\n",
       "       [ 2.15018829e+00,  2.06708279e-01],\n",
       "       [-2.10042759e-01,  8.68372577e-01],\n",
       "       [-6.55990043e-01,  3.06782702e-01],\n",
       "       [ 6.47814430e-01,  5.85212859e-01],\n",
       "       [ 1.88333704e-01, -1.44618737e-01],\n",
       "       [ 1.63105596e+00, -4.03553417e-01],\n",
       "       [ 1.25748984e+00, -3.31953143e-01],\n",
       "       [ 1.57759688e+00, -3.61194460e-01],\n",
       "       [ 3.42820667e-01, -3.03459814e-01],\n",
       "       [ 1.65798948e-01, -2.20865593e-02],\n",
       "       [ 1.98883775e+00,  6.91155344e-01],\n",
       "       [ 2.76986233e-01,  7.63763879e-01],\n",
       "       [ 5.78375447e-01,  3.65628610e-01],\n",
       "       [ 8.62807478e-01,  9.53590659e-01],\n",
       "       [ 3.85937384e-01,  9.94791321e-01],\n",
       "       [ 1.79532617e+00, -6.00029079e-01],\n",
       "       [ 1.10240388e+00,  1.91066589e-01],\n",
       "       [ 6.29961423e-01,  2.66978355e-01],\n",
       "       [ 5.75808729e-01, -5.20168443e-03],\n",
       "       [-4.07698036e-01,  6.97373696e-01],\n",
       "       [ 1.53314082e-01,  1.16837716e+00],\n",
       "       [ 1.83831785e+00, -3.42366215e-02],\n",
       "       [-1.05732659e+00,  8.84544696e-01],\n",
       "       [-6.93432043e-01,  1.08324232e+00],\n",
       "       [-1.15535166e+00,  5.11112426e-01],\n",
       "       [ 1.96687708e+00,  3.04789943e-01],\n",
       "       [-1.06655015e+00,  1.69318154e-02],\n",
       "       [-2.85811975e-01,  1.01688208e+00],\n",
       "       [ 2.15576261e+00, -4.64407087e-01],\n",
       "       [ 1.99015292e+00,  3.45283849e-01],\n",
       "       [ 1.37125751e-01,  9.32998267e-01],\n",
       "       [ 6.51669614e-01,  6.52027660e-01],\n",
       "       [ 1.65053679e+00, -2.07320161e-01],\n",
       "       [ 1.34192179e-01,  1.03359768e+00],\n",
       "       [ 1.25526047e+00, -3.98713971e-01],\n",
       "       [ 6.01387473e-01,  3.08533816e-01],\n",
       "       [ 1.24865987e+00, -2.52921977e-01],\n",
       "       [-8.45355941e-02,  3.42241334e-01],\n",
       "       [ 1.27843224e+00, -2.44761533e-01],\n",
       "       [ 1.25007856e+00, -5.10887715e-01],\n",
       "       [ 3.40404709e-01,  1.20345588e-01],\n",
       "       [ 2.01778273e+00,  2.01094700e-01],\n",
       "       [-8.44332291e-01,  5.66258494e-01],\n",
       "       [ 5.81017131e-01, -5.50111254e-01],\n",
       "       [ 2.56807274e-01,  8.09072077e-02],\n",
       "       [ 5.32096193e-01,  2.79152313e-01],\n",
       "       [ 7.32260111e-01,  6.86188321e-01],\n",
       "       [ 3.94447811e-01, -3.38333300e-01],\n",
       "       [-1.00900416e+00,  6.37795432e-02],\n",
       "       [ 6.69871959e-02,  4.24121476e-01],\n",
       "       [ 9.55698770e-01,  2.32361802e-01],\n",
       "       [-4.92400331e-02,  1.15241365e+00],\n",
       "       [ 4.89886539e-01,  6.80063337e-02],\n",
       "       [-5.52884554e-01,  1.18344185e+00],\n",
       "       [ 4.50794485e-02,  6.15196901e-01],\n",
       "       [-6.25353318e-01,  7.43705405e-01],\n",
       "       [-7.74549377e-01,  8.54024244e-01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ac73cbbfece7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#from_numpy takes a numpy element and returns torch.tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#from_numpy takes a numpy element and returns torch.tensor\n",
    "X = torch.from_numpy(X).type(torch.FloatTensor)\n",
    "y = torch.from_numpy(y).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5fe5eafd380c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#our class must extend nn.Module\n",
    "class MyClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyClassifier,self).__init__()\n",
    "        #Our network consists of 3 layers. 1 input, 1 hidden and 1 output layer\n",
    "        #This applies Linear transformation to input data. \n",
    "        self.fc1 = nn.Linear(2,3)\n",
    "        \n",
    "        #This applies linear transformation to produce output data\n",
    "        self.fc2 = nn.Linear(3,2)\n",
    "        \n",
    "    #This must be implemented\n",
    "    def forward(self,x):\n",
    "        #Output of the first layer\n",
    "        x = self.fc1(x)\n",
    "        #Activation function is Relu. Feel free to experiment with this\n",
    "        x = F.tanh(x)\n",
    "        #This produces output\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "        \n",
    "    #This function takes an input and predicts the class, (0 or 1)        \n",
    "    def predict(self,x):\n",
    "        #Apply softmax to output. \n",
    "        pred = F.softmax(self.forward(x))\n",
    "        ans = []\n",
    "        #Pick the class with maximum weight\n",
    "        for t in pred:\n",
    "            if t[0]>t[1]:\n",
    "                ans.append(0)\n",
    "            else:\n",
    "                ans.append(1)\n",
    "        return torch.tensor(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The criterion that we are going to use is CrossEntropyLoss. This is the common choice for most classification problems. Let’s train the model using ADAM(Adaptive moment estimation) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e0df96334c65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Define the optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#Initialize the model        \n",
    "model = MyClassifier()\n",
    "#Define loss criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a014df828921>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#Precit the output for Given input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m#Compute Cross entropy loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-19b925516957>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#Output of the first layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m#Activation function is Relu. Feel free to experiment with this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mOutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0m_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \"\"\"\n\u001b[0;32m-> 1368\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "#Number of epochs\n",
    "epochs = 10000\n",
    "#List to store losses\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    #Precit the output for Given input\n",
    "    y_pred = model.forward(X)\n",
    "    #Compute Cross entropy loss\n",
    "    loss = criterion(y_pred,y)\n",
    "    #Add loss to the list\n",
    "    losses.append(loss.item())\n",
    "    #Clear the previous gradients\n",
    "    optimizer.zero_grad()\n",
    "    #Compute gradients\n",
    "    loss.backward()\n",
    "    #Adjust weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(\"epochs\",i,\"loss\",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know this seems very confusing at first. All we are doing is, computing the loss. Calculating gradients and adjusting weights. implement couple of networks using PyTorch, you will get used to it for sure.\n",
    "We are done with training process. Now, let’s calculate re-submission error. It’s the accuracy that we’ve been able to achieve on the training dataset. This is a bad practice, as we should always test the performance of a model on unseen data. Never the data that we have trained the model with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fb87d6384162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-19b925516957>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#Apply softmax to output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#Pick the class with maximum weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-19b925516957>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#Output of the first layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m#Activation function is Relu. Feel free to experiment with this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mOutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0m_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \"\"\"\n\u001b[0;32m-> 1368\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(model.predict(X),y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s visualize the performance of the model by visualizing the decision boundary\n",
    " This is a function which returns the class (0 or 1) , given a single input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    #Convert into numpy element to tensor\n",
    "    x = torch.from_numpy(x).type(torch.FloatTensor)\n",
    "    #Predict and return ans\n",
    "    ans = model.predict(x)\n",
    "    return ans.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below function plots the decision boundary. This is a very useful function , it gives a visual representation of how well your model is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to plot a decision boundary.\n",
    "def plot_decision_boundary(pred_func,X,y):\n",
    "    # Set min and max values and give it some padding\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    h = 0.01\n",
    "    # Generate a grid of points with distance h between them\n",
    "    xx,yy=np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    # Predict the function value for the whole gid\n",
    "    Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    # Plot the contour and training examples\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_decision_boundary(lambda x : predict(x) ,X.numpy(), y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
