{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Random tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "tensor([[0.3099, 0.5447, 0.9396],\n",
      "        [0.7950, 0.6256, 0.5722],\n",
      "        [0.2281, 0.2580, 0.7848]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "#random tensor of size 3*3\n",
    "randten = torch.rand(3,3)\n",
    "\n",
    "#shpe of tensor\n",
    "tensor_size = randten.shape\n",
    "\n",
    "print(tensor_size)\n",
    "print(randten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Matrix_Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor_of_ones = torch.ones(3,3)\n",
    "\n",
    "#identitymatrix\n",
    "identity_tensor = torch.eye(3,3)\n",
    "\n",
    "#matrix multiplication\n",
    "print(torch.matmul(tensor_of_ones, identity_tensor))\n",
    "\n",
    "#element wise multiplication\n",
    "print(tensor_of_ones*identity_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(125.2440)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1000,1000)\n",
    "y = torch.rand(1000,1000)\n",
    "z = torch.rand(1000,1000)\n",
    "\n",
    "#matmul of x and y\n",
    "q = torch.matmul(x,y)\n",
    "\n",
    "#element wise multiplciation \n",
    "f = z*q\n",
    "\n",
    "mean_f = torch.mean(f)\n",
    "print(mean_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Backpropogation in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of z is:tensor(2.)\n",
      "Gradient of y is:tensor(-2.)\n",
      "Gradient of x is:tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(-3., requires_grad = True)\n",
    "y = torch.tensor(5., requires_grad = True)\n",
    "z = torch.tensor(-2., requires_grad = True)\n",
    "\n",
    "q = x+y\n",
    "f = q*z\n",
    "\n",
    "#trigger backpropogate\n",
    "f.backward()\n",
    "\n",
    "print('Gradient of z is:'+ str(z.grad))\n",
    "print('Gradient of y is:'+ str(y.grad))\n",
    "print('Gradient of x is:'+ str(x.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**:- If the data given is vector data/ table data, then classifiers like k- Nearrest Neighbouts, Logistic Regression, Random forests, Gradient Boosted trees, suppor vector machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Fully connected Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Weight1*********:tensor([[0.1929, 0.2076, 0.2613, 0.9514, 0.3909, 0.5953, 0.3680, 0.3325, 0.7120,\n",
      "         0.9557, 0.8313, 0.4387, 0.2443, 0.4247, 0.8682, 0.6173, 0.2603, 0.0963,\n",
      "         0.5530, 0.0026],\n",
      "        [0.1996, 0.4122, 0.8048, 0.9831, 0.3058, 0.9535, 0.3828, 0.8753, 0.8673,\n",
      "         0.8015, 0.1290, 0.5257, 0.7940, 0.3718, 0.7024, 0.2282, 0.9557, 0.7742,\n",
      "         0.5207, 0.3716],\n",
      "        [0.4132, 0.7625, 0.9978, 0.0921, 0.3423, 0.8357, 0.8160, 0.6040, 0.1387,\n",
      "         0.1174, 0.9226, 0.9420, 0.2624, 0.0460, 0.3181, 0.2657, 0.9370, 0.5795,\n",
      "         0.0422, 0.8892],\n",
      "        [0.8246, 0.5780, 0.3446, 0.7100, 0.9742, 0.4727, 0.7446, 0.7918, 0.4859,\n",
      "         0.2773, 0.6558, 0.5191, 0.8267, 0.0616, 0.5982, 0.5357, 0.0204, 0.8069,\n",
      "         0.0073, 0.6125],\n",
      "        [0.5859, 0.5832, 0.9055, 0.3593, 0.2817, 0.6560, 0.3153, 0.6997, 0.8263,\n",
      "         0.2110, 0.0165, 0.7848, 0.0948, 0.5131, 0.7170, 0.9880, 0.3411, 0.4984,\n",
      "         0.2179, 0.8982],\n",
      "        [0.3674, 0.7531, 0.6511, 0.3414, 0.8886, 0.1592, 0.4984, 0.5115, 0.3503,\n",
      "         0.9180, 0.2677, 0.7780, 0.8287, 0.4414, 0.4236, 0.9464, 0.2381, 0.8931,\n",
      "         0.6609, 0.0028],\n",
      "        [0.4243, 0.7476, 0.9411, 0.8203, 0.4730, 0.8899, 0.0789, 0.9053, 0.1640,\n",
      "         0.5341, 0.1807, 0.3766, 0.6889, 0.7298, 0.9980, 0.0718, 0.3487, 0.5989,\n",
      "         0.0664, 0.9112],\n",
      "        [0.1746, 0.2590, 0.7059, 0.6481, 0.5566, 0.2732, 0.4780, 0.4461, 0.9208,\n",
      "         0.8271, 0.8083, 0.6586, 0.8122, 0.1689, 0.6463, 0.1408, 0.9276, 0.1601,\n",
      "         0.3372, 0.6459],\n",
      "        [0.2734, 0.5800, 0.0805, 0.9279, 0.0655, 0.0778, 0.6880, 0.6829, 0.9002,\n",
      "         0.5808, 0.9410, 0.2995, 0.4959, 0.4518, 0.0928, 0.8685, 0.0298, 0.2263,\n",
      "         0.8326, 0.7714],\n",
      "        [0.0711, 0.7094, 0.5103, 0.0762, 0.9979, 0.0081, 0.2605, 0.3965, 0.1350,\n",
      "         0.7196, 0.5196, 0.1398, 0.7066, 0.7040, 0.3449, 0.1963, 0.1320, 0.2583,\n",
      "         0.3068, 0.5963]])\n",
      "**********Weight2*******:tensor([[0.2981, 0.1510, 0.7926, 0.5508, 0.6779, 0.1566, 0.7912, 0.5627, 0.5425,\n",
      "         0.0514, 0.0126, 0.3286, 0.9052, 0.9443, 0.2687, 0.9097, 0.8148, 0.6970,\n",
      "         0.6048, 0.6981],\n",
      "        [0.9510, 0.4196, 0.2643, 0.4462, 0.0141, 0.0634, 0.7956, 0.5308, 0.8159,\n",
      "         0.0155, 0.5486, 0.9235, 0.9077, 0.2528, 0.9978, 0.2855, 0.3869, 0.3329,\n",
      "         0.0189, 0.1670],\n",
      "        [0.9378, 0.1158, 0.9117, 0.9631, 0.5600, 0.2332, 0.2305, 0.4325, 0.5708,\n",
      "         0.1781, 0.1567, 0.2101, 0.2571, 0.5856, 0.1640, 0.0587, 0.3386, 0.5407,\n",
      "         0.5304, 0.6624],\n",
      "        [0.7939, 0.4066, 0.9254, 0.9846, 0.1884, 0.3142, 0.7142, 0.8074, 0.3833,\n",
      "         0.3881, 0.2889, 0.8225, 0.5122, 0.0074, 0.3442, 0.1543, 0.5296, 0.0460,\n",
      "         0.7711, 0.2893],\n",
      "        [0.6349, 0.4199, 0.3616, 0.5436, 0.1791, 0.5940, 0.4090, 0.5155, 0.1176,\n",
      "         0.3481, 0.3634, 0.5603, 0.5770, 0.1751, 0.7105, 0.9751, 0.9860, 0.6326,\n",
      "         0.0887, 0.7798],\n",
      "        [0.0454, 0.8399, 0.1033, 0.6653, 0.7010, 0.2736, 0.6470, 0.6060, 0.8534,\n",
      "         0.6192, 0.7727, 0.2031, 0.4789, 0.3219, 0.0616, 0.2199, 0.9424, 0.8551,\n",
      "         0.1726, 0.4906],\n",
      "        [0.9119, 0.2603, 0.2222, 0.4377, 0.9327, 0.1318, 0.8829, 0.5374, 0.8584,\n",
      "         0.2933, 0.0186, 0.6202, 0.6235, 0.2266, 0.0754, 0.3338, 0.1782, 0.4140,\n",
      "         0.5616, 0.8971],\n",
      "        [0.4907, 0.4239, 0.4871, 0.6286, 0.3108, 0.4281, 0.8313, 0.6471, 0.3718,\n",
      "         0.5399, 0.5686, 0.3580, 0.4686, 0.8401, 0.5086, 0.9788, 0.1142, 0.4075,\n",
      "         0.2410, 0.4641],\n",
      "        [0.3337, 0.3097, 0.9501, 0.4120, 0.7217, 0.8781, 0.8894, 0.6845, 0.2183,\n",
      "         0.8137, 0.6283, 0.7897, 0.8314, 0.8886, 0.5484, 0.8342, 0.4754, 0.7568,\n",
      "         0.5577, 0.9696],\n",
      "        [0.6591, 0.9626, 0.5416, 0.5752, 0.4076, 0.2916, 0.3796, 0.9066, 0.7422,\n",
      "         0.3157, 0.1187, 0.4548, 0.5369, 0.0441, 0.7413, 0.6351, 0.2441, 0.1189,\n",
      "         0.1701, 0.3223],\n",
      "        [0.9988, 0.6517, 0.1109, 0.2177, 0.7817, 0.5514, 0.9725, 0.0259, 0.6439,\n",
      "         0.5295, 0.0301, 0.6298, 0.7997, 0.7406, 0.2556, 0.7037, 0.9371, 0.7602,\n",
      "         0.2278, 0.9212],\n",
      "        [0.9080, 0.9455, 0.8208, 0.8767, 0.5955, 0.9841, 0.3756, 0.9156, 0.3191,\n",
      "         0.7130, 0.4717, 0.8930, 0.5984, 0.6875, 0.4060, 0.5385, 0.6975, 0.8700,\n",
      "         0.5680, 0.3923],\n",
      "        [0.8884, 0.9271, 0.8341, 0.2907, 0.2786, 0.1505, 0.6029, 0.5324, 0.0821,\n",
      "         0.5788, 0.5852, 0.8764, 0.0872, 0.3202, 0.0506, 0.0289, 0.0232, 0.7726,\n",
      "         0.7349, 0.4823],\n",
      "        [0.7381, 0.7029, 0.3882, 0.3943, 0.8949, 0.2532, 0.4654, 0.4327, 0.8294,\n",
      "         0.4457, 0.8815, 0.4834, 0.1991, 0.8199, 0.6756, 0.9309, 0.6065, 0.9704,\n",
      "         0.2909, 0.7101],\n",
      "        [0.2544, 0.2818, 0.7974, 0.6978, 0.4607, 0.3889, 0.1847, 0.0128, 0.1447,\n",
      "         0.8959, 0.8891, 0.1687, 0.4399, 0.9013, 0.9595, 0.6392, 0.7235, 0.1570,\n",
      "         0.8264, 0.0443],\n",
      "        [0.3856, 0.9017, 0.5932, 0.0815, 0.0184, 0.6251, 0.0601, 0.3079, 0.4468,\n",
      "         0.0976, 0.3579, 0.2397, 0.2441, 0.2533, 0.4322, 0.6825, 0.8667, 0.1895,\n",
      "         0.1148, 0.7841],\n",
      "        [0.3789, 0.3052, 0.7921, 0.1401, 0.1361, 0.3998, 0.8993, 0.4062, 0.7542,\n",
      "         0.1421, 0.8525, 0.2296, 0.2727, 0.1736, 0.0490, 0.3170, 0.8261, 0.6446,\n",
      "         0.3117, 0.6713],\n",
      "        [0.2301, 0.4742, 0.1778, 0.8582, 0.6651, 0.6263, 0.7709, 0.9372, 0.7028,\n",
      "         0.8471, 0.6822, 0.4454, 0.8036, 0.5301, 0.2149, 0.1818, 0.0188, 0.5394,\n",
      "         0.0642, 0.2569],\n",
      "        [0.6721, 0.5809, 0.1136, 0.3470, 0.6104, 0.7315, 0.8818, 0.9619, 0.9543,\n",
      "         0.9137, 0.8187, 0.8434, 0.8912, 0.7421, 0.9057, 0.6009, 0.2721, 0.7012,\n",
      "         0.6933, 0.0353],\n",
      "        [0.2217, 0.3936, 0.0958, 0.6882, 0.4355, 0.0343, 0.5494, 0.3643, 0.8921,\n",
      "         0.7242, 0.0249, 0.2556, 0.1036, 0.2036, 0.2687, 0.0881, 0.0858, 0.7663,\n",
      "         0.9215, 0.8133]])\n",
      "********Weight3*********:tensor([[0.7962, 0.1137, 0.4100, 0.6097],\n",
      "        [0.2859, 0.0186, 0.0191, 0.2670],\n",
      "        [0.7609, 0.4011, 0.1240, 0.9221],\n",
      "        [0.6416, 0.4914, 0.1172, 0.3570],\n",
      "        [0.0698, 0.6411, 0.3681, 0.5594],\n",
      "        [0.0530, 0.7716, 0.8986, 0.5675],\n",
      "        [0.8999, 0.5144, 0.4873, 0.5615],\n",
      "        [0.1322, 0.8092, 0.7111, 0.3031],\n",
      "        [0.3825, 0.1985, 0.5780, 0.6093],\n",
      "        [0.6804, 0.9790, 0.3090, 0.2103],\n",
      "        [0.5358, 0.0157, 0.3264, 0.6308],\n",
      "        [0.2562, 0.0479, 0.3836, 0.5289],\n",
      "        [0.8048, 0.3251, 0.4448, 0.7717],\n",
      "        [0.0204, 0.0869, 0.1509, 0.0682],\n",
      "        [0.7216, 0.6246, 0.7354, 0.6765],\n",
      "        [0.2748, 0.9889, 0.4664, 0.2232],\n",
      "        [0.9688, 0.9937, 0.5709, 0.7095],\n",
      "        [0.8014, 0.4870, 0.0038, 0.0123],\n",
      "        [0.2526, 0.6890, 0.9540, 0.8999],\n",
      "        [0.4144, 0.0633, 0.6935, 0.0897]])\n",
      "********Hidden_layer*******:tensor([1.6817, 2.6603, 3.0316, 3.3290, 2.3620, 2.6106, 2.0970, 3.1224, 3.0853,\n",
      "        3.3311, 2.2587, 2.7585, 2.6930, 2.2074, 3.0962, 2.9150, 1.9694, 2.4838,\n",
      "        2.1932, 2.3764])\n",
      "********Hidden_layer*******:tensor([26.7569, 24.4962, 23.0749, 24.7171, 22.5610, 19.1981, 29.4953, 25.6724,\n",
      "        26.6954, 22.5028, 21.4744, 24.3265, 25.4025, 23.5824, 21.4533, 25.2695,\n",
      "        24.0383, 26.9616, 19.3891, 26.5256])\n",
      "tensor([241.6459, 219.7063, 207.2429, 226.8069])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input_layer = torch.rand(10)\n",
    "\n",
    "weight1 = torch.rand(10,20)\n",
    "weight2 = torch.rand(20,20)\n",
    "weight3 = torch.rand(20,4)\n",
    "\n",
    "hidden_layer1 = torch.matmul(input_layer, weight1)\n",
    "hidden_layer2 = torch.matmul(h1,weight2)\n",
    "\n",
    "output_layer = torch.matmul(hidden_layer2,weight3)\n",
    "\n",
    "print('*******Weight1*********:'+ str(weight1))\n",
    "print('**********Weight2*******:'+ str(weight2))\n",
    "print('********Weight3*********:'+ str(weight3))\n",
    "print('********Hidden_layer*******:'+ str(hidden_layer1))\n",
    "print('********Hidden_layer*******:'+ str(hidden_layer2))\n",
    "print(output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. NN with Pytorch style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1  = nn.Linear(10,20)\n",
    "        self.fc2 = nn.Linear(20,20)\n",
    "        self.output = nn.Linear(20,4)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "input_layer = torch.rand(10)\n",
    "net = Net()\n",
    "result = net(input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0950,  0.2826, -0.1608,  0.0466], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. ReLU Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 0.])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "relu = nn.ReLU()\n",
    "\n",
    "tensor = torch.tensor([2.,-4.])\n",
    "\n",
    "print(relu(tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Loss in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0117)\n"
     ]
    }
   ],
   "source": [
    "weights = torch.tensor([[-1.2,0.12,4.8]])#3 classes\n",
    "ground_truth = torch.tensor([2])#2 class, i.e 4.8\n",
    "\n",
    "#loss criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#compute and print the loss\n",
    "loss = criterion(weights,ground_truth)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.3091)\n"
     ]
    }
   ],
   "source": [
    "weights = torch.rand(1,1000)#1000 classes\n",
    "ground_truth = torch.tensor([111])# 111th class\n",
    "\n",
    "#loss criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#compute and print the loss\n",
    "loss = criterion(weights,ground_truth)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.2131e-01, 9.3262e-02, 5.5792e-01, 5.1858e-01, 8.3528e-01, 8.7645e-01,\n",
      "         5.6055e-01, 4.9068e-01, 5.6340e-01, 6.1148e-01, 2.4800e-02, 2.1949e-01,\n",
      "         8.9594e-01, 6.6833e-01, 8.9418e-01, 6.1452e-03, 3.4013e-02, 4.5388e-02,\n",
      "         7.9158e-01, 6.2539e-01, 5.0739e-01, 9.6911e-01, 5.6914e-01, 3.4309e-01,\n",
      "         1.3020e-01, 9.4077e-01, 3.4075e-01, 6.7388e-01, 3.3395e-02, 1.1702e-01,\n",
      "         1.1168e-01, 6.8564e-01, 6.5434e-01, 9.8178e-01, 5.1352e-01, 7.2302e-01,\n",
      "         3.9073e-01, 6.5690e-01, 3.8082e-01, 2.7050e-01, 8.1303e-01, 7.9205e-01,\n",
      "         5.9373e-01, 1.9644e-01, 2.5864e-01, 3.4575e-01, 6.0154e-01, 2.5141e-01,\n",
      "         5.6148e-01, 8.9419e-01, 1.6352e-02, 2.0610e-01, 8.9592e-01, 9.1691e-01,\n",
      "         6.7202e-01, 9.9607e-01, 5.8632e-01, 7.5589e-01, 9.2536e-01, 1.6930e-01,\n",
      "         2.0008e-01, 8.5252e-01, 4.2552e-01, 3.1710e-01, 4.0187e-02, 6.0905e-01,\n",
      "         9.0935e-01, 9.7210e-01, 7.5477e-01, 7.0050e-01, 6.3378e-01, 1.9157e-01,\n",
      "         7.6884e-01, 6.2021e-02, 5.4545e-01, 1.5733e-01, 8.3166e-01, 6.4927e-01,\n",
      "         5.1632e-01, 8.3344e-01, 6.8626e-01, 2.2071e-01, 2.3776e-01, 2.6669e-01,\n",
      "         6.5792e-01, 2.4034e-01, 5.1641e-01, 9.0140e-01, 1.7827e-01, 2.7134e-01,\n",
      "         1.8993e-01, 1.1435e-01, 3.4249e-01, 4.2469e-01, 5.5603e-02, 9.5953e-01,\n",
      "         8.6255e-01, 4.2088e-03, 8.0714e-01, 1.7936e-01, 7.0933e-01, 6.0776e-01,\n",
      "         7.1598e-01, 4.9976e-01, 6.0094e-01, 9.7252e-01, 1.1278e-01, 6.3500e-01,\n",
      "         3.3229e-01, 5.8601e-01, 1.1506e-01, 1.3637e-01, 7.4467e-01, 4.7059e-01,\n",
      "         6.2913e-01, 1.6723e-01, 4.2654e-01, 8.1443e-02, 8.9425e-01, 8.8781e-01,\n",
      "         3.1695e-01, 3.5223e-01, 9.3952e-02, 8.5711e-01, 3.4190e-01, 7.4635e-01,\n",
      "         2.4503e-01, 4.0032e-01, 4.0505e-01, 9.0301e-02, 9.4301e-01, 8.2163e-01,\n",
      "         3.5004e-01, 9.7940e-01, 3.2446e-02, 3.1229e-01, 1.0818e-01, 7.2230e-01,\n",
      "         4.2174e-02, 4.5413e-01, 9.3532e-04, 6.6848e-01, 2.0245e-01, 8.2986e-01,\n",
      "         6.2832e-01, 3.6282e-01, 1.3872e-02, 4.2854e-01, 1.1736e-01, 8.6479e-01,\n",
      "         2.8620e-03, 8.0013e-02, 2.1663e-01, 4.0733e-01, 2.7628e-01, 3.1197e-01,\n",
      "         6.2654e-01, 1.0256e-01, 3.3836e-03, 2.4128e-01, 4.6399e-02, 5.7331e-01,\n",
      "         8.9331e-01, 4.4362e-01, 1.2979e-01, 7.4854e-01, 2.7926e-01, 4.1055e-02,\n",
      "         2.6499e-01, 5.2640e-01, 7.2150e-01, 7.9364e-01, 9.5056e-01, 1.1417e-01,\n",
      "         9.1207e-01, 5.0794e-01, 2.7201e-02, 6.3134e-02, 4.9165e-01, 6.2578e-01,\n",
      "         5.9098e-01, 3.6820e-01, 8.4617e-03, 5.1866e-01, 2.6962e-01, 5.7562e-01,\n",
      "         8.6273e-01, 4.9547e-01, 7.8403e-01, 1.3188e-01, 5.1927e-01, 3.6428e-01,\n",
      "         8.4886e-01, 7.9506e-01, 1.3025e-01, 3.3255e-01, 4.0779e-01, 1.4039e-01,\n",
      "         4.6509e-01, 8.5651e-01, 5.4729e-01, 9.8801e-01, 7.2972e-01, 2.6110e-01,\n",
      "         6.0300e-01, 3.9585e-01, 6.4468e-01, 5.7782e-01, 7.7748e-02, 4.7391e-01,\n",
      "         2.6860e-01, 6.3355e-01, 1.1521e-01, 8.5204e-01, 3.9993e-01, 6.1906e-01,\n",
      "         9.6695e-01, 6.5236e-01, 2.1317e-01, 1.7637e-01, 3.0464e-01, 5.9455e-01,\n",
      "         4.0610e-01, 4.6690e-01, 2.0864e-01, 8.8400e-01, 5.5917e-01, 5.0855e-01,\n",
      "         2.2593e-01, 3.0920e-01, 2.2132e-02, 5.6885e-01, 9.7336e-01, 9.4592e-02,\n",
      "         5.3296e-01, 2.7598e-01, 6.6846e-01, 9.9573e-02, 5.9830e-01, 9.7912e-01,\n",
      "         6.6685e-01, 4.3456e-01, 8.2052e-01, 7.2118e-02, 3.5742e-01, 8.3633e-01,\n",
      "         7.4427e-01, 7.1537e-01, 1.4189e-01, 5.8725e-01, 3.6954e-02, 3.5831e-01,\n",
      "         3.3719e-01, 9.5911e-01, 6.6681e-01, 3.5995e-01, 1.5376e-01, 5.1443e-01,\n",
      "         6.5287e-01, 8.0746e-01, 3.6430e-02, 2.5742e-01, 5.8717e-01, 5.0202e-01,\n",
      "         6.4951e-01, 4.7946e-01, 6.1271e-01, 6.0517e-01, 2.9203e-01, 9.7213e-01,\n",
      "         1.7528e-01, 9.4344e-01, 3.0318e-01, 5.5444e-01, 8.1868e-01, 7.6800e-01,\n",
      "         3.3790e-01, 7.8608e-01, 5.1781e-01, 6.1202e-01, 5.9544e-01, 9.7812e-01,\n",
      "         1.3802e-01, 4.4896e-01, 4.5925e-01, 7.5212e-01, 4.4904e-01, 3.8900e-01,\n",
      "         2.8004e-01, 6.7850e-01, 5.4752e-01, 3.3193e-01, 2.2387e-01, 7.2032e-01,\n",
      "         8.9488e-01, 9.3812e-01, 7.0197e-01, 5.6257e-01, 1.8553e-01, 4.6453e-01,\n",
      "         4.8428e-02, 7.2005e-02, 4.5634e-01, 3.0094e-01, 3.9073e-01, 2.0710e-01,\n",
      "         1.0855e-01, 8.4844e-01, 4.2400e-01, 4.5364e-01, 2.3662e-02, 7.9771e-01,\n",
      "         6.5343e-01, 8.8843e-01, 9.3325e-01, 6.2545e-01, 2.0348e-01, 4.4759e-02,\n",
      "         1.7329e-01, 1.0084e-01, 8.8633e-01, 6.0514e-01, 2.3006e-01, 9.1437e-01,\n",
      "         2.2173e-01, 4.8332e-01, 4.2113e-01, 5.0683e-01, 3.9087e-01, 9.7740e-01,\n",
      "         1.7677e-01, 9.8720e-02, 9.9864e-01, 1.6399e-01, 5.6536e-01, 8.9951e-01,\n",
      "         1.1215e-01, 2.2140e-01, 5.1065e-01, 1.6494e-01, 4.9659e-01, 9.0296e-01,\n",
      "         6.0357e-01, 3.9097e-01, 4.8784e-01, 7.8129e-01, 6.2516e-01, 4.8602e-01,\n",
      "         4.3026e-01, 1.0755e-01, 2.3040e-01, 7.6213e-01, 7.2609e-01, 6.4146e-01,\n",
      "         9.9463e-01, 3.2254e-01, 5.7840e-02, 1.6944e-02, 4.7590e-01, 4.7019e-02,\n",
      "         5.4052e-01, 4.1557e-01, 6.2679e-01, 4.4021e-01, 1.9724e-01, 4.7266e-01,\n",
      "         5.8676e-02, 4.3726e-01, 6.9871e-01, 1.5136e-02, 8.5059e-01, 1.7422e-01,\n",
      "         9.5359e-01, 7.4047e-01, 9.3353e-01, 2.4769e-01, 2.7993e-01, 8.2570e-01,\n",
      "         5.5754e-01, 1.1583e-01, 4.2791e-01, 1.7476e-01, 5.7998e-01, 4.6395e-01,\n",
      "         5.6649e-01, 2.8835e-01, 4.0008e-01, 9.3194e-01, 8.7274e-01, 4.0971e-01,\n",
      "         7.9929e-01, 5.2482e-01, 1.2728e-01, 3.7509e-01, 7.7141e-01, 8.1522e-01,\n",
      "         1.2986e-02, 9.3329e-01, 4.3898e-01, 6.8555e-01, 5.1309e-01, 1.7450e-01,\n",
      "         6.8273e-01, 3.0870e-02, 2.8328e-01, 1.5709e-01, 8.3647e-01, 6.5955e-01,\n",
      "         1.1913e-02, 5.6169e-01, 3.6150e-01, 3.0236e-01, 1.5877e-01, 6.8034e-01,\n",
      "         8.4768e-01, 9.0411e-01, 1.6343e-01, 4.0952e-01, 3.8171e-01, 6.0725e-01,\n",
      "         7.5091e-01, 2.9970e-01, 7.9935e-01, 4.7929e-01, 2.0399e-03, 9.7037e-01,\n",
      "         9.6024e-01, 2.7404e-01, 5.9077e-01, 2.2321e-01, 8.4144e-01, 6.7816e-01,\n",
      "         4.6257e-01, 6.3811e-01, 9.3395e-01, 4.1503e-01, 5.1647e-01, 5.5652e-01,\n",
      "         4.1721e-01, 4.9843e-02, 2.2775e-01, 6.5189e-01, 3.2635e-01, 3.8753e-01,\n",
      "         1.5997e-01, 3.5004e-01, 8.7506e-01, 9.2962e-01, 6.0379e-01, 7.6175e-01,\n",
      "         4.6632e-01, 7.3008e-01, 7.0321e-01, 9.1350e-01, 3.7695e-01, 7.8250e-01,\n",
      "         5.5690e-01, 4.9898e-01, 4.6907e-01, 5.2375e-01, 8.1404e-01, 1.6504e-01,\n",
      "         5.6483e-01, 6.7573e-01, 5.9891e-01, 6.5152e-01, 2.0305e-01, 2.9583e-01,\n",
      "         2.3365e-01, 8.0732e-01, 5.3467e-01, 5.6594e-01, 3.4155e-01, 9.2524e-01,\n",
      "         1.4557e-01, 1.7277e-01, 9.5253e-01, 5.5041e-01, 5.0352e-01, 6.9716e-01,\n",
      "         2.0505e-01, 6.8206e-01, 5.7752e-01, 3.9860e-01, 7.5931e-01, 2.8785e-01,\n",
      "         6.9854e-01, 9.7949e-01, 5.1964e-01, 2.5553e-01, 2.5554e-01, 6.0320e-01,\n",
      "         8.3766e-01, 7.1751e-02, 2.8667e-01, 9.9811e-01, 6.8266e-01, 8.9846e-01,\n",
      "         3.7920e-01, 7.9933e-01, 7.1820e-01, 5.1257e-01, 9.4664e-01, 3.9013e-01,\n",
      "         7.2322e-01, 4.5539e-01, 2.3760e-01, 2.7012e-01, 9.0067e-01, 4.0371e-01,\n",
      "         4.3307e-01, 2.0766e-01, 2.3712e-01, 8.6769e-01, 2.9476e-01, 3.1725e-01,\n",
      "         6.6016e-01, 1.3723e-01, 9.0874e-01, 5.6264e-02, 6.0043e-01, 1.9857e-01,\n",
      "         7.4297e-01, 6.9363e-01, 3.5642e-01, 1.5273e-01, 8.1912e-01, 2.0210e-01,\n",
      "         8.9521e-01, 8.1112e-01, 1.9659e-01, 1.7416e-01, 9.9417e-02, 9.1371e-01,\n",
      "         7.0231e-01, 4.5881e-01, 1.1021e-01, 2.9641e-01, 2.9235e-01, 8.8518e-01,\n",
      "         7.9762e-01, 1.6289e-01, 8.7320e-01, 2.1980e-01, 5.5727e-01, 4.4857e-01,\n",
      "         5.7905e-01, 5.8367e-01, 2.3175e-01, 5.9758e-01, 6.5029e-02, 5.9737e-01,\n",
      "         4.1835e-01, 7.4598e-01, 1.5654e-01, 8.7455e-01, 6.8500e-01, 3.6754e-01,\n",
      "         1.9854e-01, 5.4938e-01, 2.1384e-01, 7.3686e-01, 2.1080e-01, 1.2903e-01,\n",
      "         9.2546e-01, 8.9209e-01, 1.0922e-01, 7.7866e-01, 4.6419e-02, 9.4072e-01,\n",
      "         8.3863e-01, 1.5361e-01, 7.2193e-01, 3.1961e-02, 3.5358e-01, 3.1069e-01,\n",
      "         9.6727e-01, 5.2393e-01, 9.2354e-01, 4.7750e-01, 2.4854e-01, 2.7607e-01,\n",
      "         7.6653e-01, 8.5971e-01, 7.5968e-01, 8.6105e-01, 2.2999e-01, 9.9621e-01,\n",
      "         8.4988e-01, 6.8287e-01, 6.7184e-01, 3.9650e-01, 2.2723e-01, 9.7367e-01,\n",
      "         9.7233e-01, 2.0650e-01, 4.5801e-01, 5.2374e-02, 2.1568e-01, 1.1563e-01,\n",
      "         3.9315e-01, 9.1304e-01, 2.4000e-03, 1.9302e-01, 5.2353e-01, 8.8075e-01,\n",
      "         1.1735e-01, 8.6825e-01, 5.5954e-01, 3.4890e-01, 2.8480e-01, 4.0810e-01,\n",
      "         2.1812e-01, 9.0389e-01, 5.4363e-02, 7.6263e-01, 4.3297e-01, 4.5040e-01,\n",
      "         5.4074e-02, 4.0440e-01, 6.0724e-01, 6.5947e-01, 5.1040e-01, 1.5444e-01,\n",
      "         6.0438e-01, 9.0979e-01, 7.5510e-01, 9.0353e-01, 6.0164e-01, 7.8149e-01,\n",
      "         9.9039e-01, 7.4565e-01, 7.4871e-01, 6.0000e-01, 1.7699e-01, 7.0930e-01,\n",
      "         6.5561e-01, 8.1171e-01, 7.0281e-01, 9.0265e-01, 5.7180e-01, 5.9127e-01,\n",
      "         6.0065e-01, 3.4246e-01, 4.6813e-01, 9.4623e-01, 6.0317e-01, 4.4842e-01,\n",
      "         8.4178e-01, 2.5501e-01, 3.2636e-01, 2.8749e-01, 1.8989e-01, 4.8480e-01,\n",
      "         4.7228e-01, 3.0351e-01, 7.6957e-02, 9.4645e-01, 9.9000e-01, 8.1053e-01,\n",
      "         1.8275e-01, 7.0305e-01, 3.4762e-01, 2.4926e-01, 6.5311e-01, 3.7504e-02,\n",
      "         2.2436e-01, 6.7442e-01, 7.5590e-01, 1.4453e-01, 7.8491e-01, 3.4814e-01,\n",
      "         8.4708e-01, 7.1924e-01, 6.5129e-01, 4.0180e-01, 8.7312e-01, 3.2193e-01,\n",
      "         1.6555e-01, 9.0744e-01, 9.6728e-01, 1.2103e-03, 9.6912e-01, 8.5236e-01,\n",
      "         3.2514e-02, 5.2844e-01, 5.1222e-01, 3.6726e-01, 7.6314e-01, 1.1074e-01,\n",
      "         7.1526e-01, 6.8484e-01, 6.6899e-01, 5.4664e-01, 9.4359e-01, 9.0733e-01,\n",
      "         5.3458e-01, 4.4651e-01, 3.4075e-01, 9.2450e-01, 7.0716e-01, 9.0327e-01,\n",
      "         1.3609e-01, 9.5566e-01, 5.4799e-01, 4.2069e-01, 5.0893e-01, 5.2499e-01,\n",
      "         3.0953e-01, 7.2521e-01, 6.7464e-01, 5.3378e-03, 2.9390e-01, 9.6253e-01,\n",
      "         6.2254e-01, 2.4810e-02, 1.6388e-01, 9.4788e-01, 2.7134e-01, 3.2707e-01,\n",
      "         1.4721e-01, 4.7923e-02, 5.8891e-01, 2.1478e-01, 5.2380e-02, 8.3711e-01,\n",
      "         5.8575e-01, 1.7935e-01, 2.9232e-01, 8.9592e-01, 8.2766e-01, 7.6125e-01,\n",
      "         9.0885e-01, 8.4831e-01, 5.4740e-01, 3.3150e-01, 6.8167e-01, 4.8056e-01,\n",
      "         8.4233e-01, 2.7028e-01, 4.3732e-01, 2.2017e-01, 5.2302e-01, 4.2580e-01,\n",
      "         1.9646e-01, 5.9448e-01, 7.6984e-01, 5.4896e-01, 3.9062e-01, 1.6759e-01,\n",
      "         6.1136e-01, 1.5567e-01, 8.7785e-01, 1.2143e-01, 1.8818e-01, 1.9560e-01,\n",
      "         7.2700e-01, 8.8827e-01, 8.9704e-01, 4.4706e-01, 2.2386e-02, 1.4588e-01,\n",
      "         5.0941e-01, 1.1340e-01, 3.3038e-02, 1.1343e-01, 2.5272e-02, 8.9579e-01,\n",
      "         2.1062e-01, 8.5688e-01, 9.5275e-01, 5.3282e-02, 4.6457e-01, 2.1947e-01,\n",
      "         5.0838e-01, 2.7633e-01, 5.3531e-02, 6.6149e-01, 8.4635e-01, 9.5341e-01,\n",
      "         3.4741e-01, 5.2226e-01, 6.8482e-01, 6.7447e-02, 8.8415e-01, 6.9974e-01,\n",
      "         1.0147e-01, 7.6322e-01, 4.4744e-01, 3.4754e-01, 9.4607e-01, 4.2079e-01,\n",
      "         8.3654e-01, 3.7145e-01, 3.8721e-01, 9.5647e-01, 4.6115e-01, 4.4270e-01,\n",
      "         6.3181e-01, 9.2181e-01, 5.6119e-01, 6.5708e-01, 8.0032e-01, 7.6689e-01,\n",
      "         7.9190e-01, 3.3654e-01, 9.7112e-01, 3.5101e-01, 1.5588e-01, 4.2542e-01,\n",
      "         1.3427e-02, 2.0906e-01, 4.9632e-01, 5.6547e-02, 4.0638e-03, 1.2768e-01,\n",
      "         3.2579e-01, 4.9454e-01, 3.5308e-01, 6.5953e-01, 8.2486e-01, 6.1289e-01,\n",
      "         9.5137e-01, 5.6205e-01, 6.5668e-01, 4.7742e-01, 1.2202e-01, 6.7745e-01,\n",
      "         7.6100e-01, 5.5247e-01, 2.1314e-01, 4.6769e-01, 2.5799e-02, 2.5686e-01,\n",
      "         6.2464e-01, 3.8995e-01, 5.0541e-01, 2.6774e-01, 9.6514e-01, 6.3213e-02,\n",
      "         8.0269e-01, 1.5011e-01, 6.3084e-01, 4.9682e-01, 2.8608e-01, 3.6527e-02,\n",
      "         8.1554e-01, 2.0924e-01, 8.7959e-01, 5.5688e-01, 2.0024e-01, 5.7515e-01,\n",
      "         6.9678e-01, 9.5066e-01, 7.1211e-01, 7.7460e-01, 2.6411e-01, 4.9931e-01,\n",
      "         2.8922e-01, 7.9976e-01, 7.5427e-01, 1.0362e-01, 6.1801e-01, 7.7261e-01,\n",
      "         2.7144e-01, 5.1471e-01, 7.4092e-01, 3.4056e-03, 4.3993e-01, 5.1607e-01,\n",
      "         3.5964e-02, 2.8109e-01, 3.9040e-01, 6.3974e-01, 3.8444e-02, 1.4941e-01,\n",
      "         6.9018e-01, 4.0681e-01, 6.3872e-02, 3.9578e-01, 6.1238e-01, 6.5909e-01,\n",
      "         2.9459e-01, 3.6940e-01, 3.1568e-03, 1.8793e-01, 1.4297e-01, 9.2894e-01,\n",
      "         2.2037e-01, 7.2174e-01, 7.2846e-01, 5.0637e-01, 6.1656e-01, 6.1726e-01,\n",
      "         1.3491e-01, 7.4313e-01, 5.1616e-01, 7.1984e-01, 3.0570e-01, 2.7605e-01,\n",
      "         2.7521e-01, 7.4915e-01, 3.0508e-01, 3.4749e-01, 8.6010e-01, 6.1809e-01,\n",
      "         4.2812e-01, 3.9290e-01, 9.4881e-01, 6.1534e-01, 2.7864e-01, 4.8430e-01,\n",
      "         9.1092e-02, 9.6172e-01, 7.5370e-01, 9.7127e-01, 2.1340e-01, 5.8997e-01,\n",
      "         2.6208e-01, 6.6810e-01, 1.5041e-01, 9.3990e-01, 4.3981e-01, 8.8223e-02,\n",
      "         5.6245e-02, 9.7769e-01, 5.6999e-01, 4.4047e-01, 4.0730e-01, 4.2669e-01,\n",
      "         6.1897e-01, 7.0402e-01, 9.6333e-01, 9.4103e-01, 2.0491e-01, 1.1022e-01,\n",
      "         9.2378e-01, 8.5839e-01, 9.1977e-01, 3.0016e-01, 2.8059e-01, 2.4479e-01,\n",
      "         6.6341e-01, 3.5177e-01, 7.3824e-01, 6.3581e-01, 3.7771e-01, 6.0988e-01,\n",
      "         9.3945e-01, 1.2803e-01, 7.8640e-01, 6.2786e-01, 1.3668e-01, 2.0535e-02,\n",
      "         9.1388e-01, 3.3607e-01, 6.7483e-01, 9.3568e-02, 7.3814e-01, 3.2573e-01,\n",
      "         9.0469e-01, 5.4557e-01, 4.0268e-01, 8.9486e-01, 7.6730e-01, 9.4282e-01,\n",
      "         5.2881e-01, 6.3926e-01, 2.1678e-01, 3.2584e-01, 9.5570e-01, 8.4271e-01,\n",
      "         8.9064e-01, 3.0763e-02, 5.6413e-01, 3.1407e-01, 7.2018e-02, 2.3906e-01,\n",
      "         2.7392e-01, 5.6265e-01, 1.7028e-01, 1.9827e-01, 3.8010e-02, 4.9006e-01,\n",
      "         5.7586e-01, 7.3264e-01, 5.5099e-01, 5.2791e-02, 8.6458e-01, 6.9247e-01,\n",
      "         5.6064e-01, 7.8092e-01, 5.6068e-02, 9.6014e-01, 8.9168e-01, 8.4454e-01,\n",
      "         3.0015e-01, 3.0405e-01, 8.3213e-02, 1.8620e-01]])\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([111])\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Dataset and Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data\n",
    "import torchvision.transform as transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.4914,0.48216,0.44653),\n",
    "                                                   (0.24703,0.24349,0.26159))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2 Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root = './data', train = True,download = True, transform = transform)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root = './data',train = False, download = True, transform =transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size = 32, shuffle = True, num_workers = 4)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 32, shuffle = False, num_workers = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.3 NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1= nn.Linear(32*32*3, 500)\n",
    "        self.fc2 =nn.Linear(500, 10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer  = optim.Adam(net.parameters(), lr = 3e-4)\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i,data in enumerate(trainloader,0):\n",
    "        #get inputs\n",
    "        inputs,labels = data\n",
    "        inputs = inputs.view(-1,32*32*8)\n",
    "        \n",
    "        #zero parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward +backward+optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5 predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct,total  =0,0\n",
    "predictions = []\n",
    "net.eval()\n",
    "\n",
    "for i,data in enumerate(testloader,0):\n",
    "    inputs,labels = data\n",
    "    outputs = net(inputs)\n",
    "    _,predicted = torch.max(outputs.data,1)\n",
    "    predictions.append(outputs)\n",
    "    total += labels.size(0)\n",
    "    correct+= (predicted == labels).sum().item()\n",
    "    \n",
    "print('Theh testing set accuracy of the network is : %d %%'%(100* correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN in pytroch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa264434278>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn \n",
    "\n",
    "image = torch.rand(32,32,3)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN in OOP way(pytroch way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn \n",
    "\n",
    "image = torch.rand(16,3,32,32)\n",
    "conv_filter = torch.nn.Conv2d(in_channels = 3, out_channels = 1, kernel_size = 5, stride = 1, padding =0)\n",
    "output_feature = conv_filter(image)\n",
    "\n",
    "print(output_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 5, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "conv_filter = torch.nn.Conv2d(in_channels = 3, out_channels = 5, kernel_size = 5, stride = 1, padding =1)\n",
    "output_feature = conv_filter(image)\n",
    "\n",
    "print(output_feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN in Functional way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5380, 0.7980, 1.1427,  ..., 0.6116, 0.7664, 0.6677],\n",
      "          [0.7627, 1.8679, 1.3840,  ..., 1.0120, 1.1340, 1.3212],\n",
      "          [1.1458, 1.3696, 1.5389,  ..., 0.8573, 1.2407, 1.0606],\n",
      "          ...,\n",
      "          [0.4445, 0.8040, 0.8987,  ..., 1.2964, 1.1172, 0.5513],\n",
      "          [0.6019, 1.0964, 1.3154,  ..., 1.2381, 0.7603, 1.1238],\n",
      "          [0.5955, 0.7890, 0.4052,  ..., 0.4812, 0.5626, 0.6742]],\n",
      "\n",
      "         [[0.9879, 1.5972, 1.5837,  ..., 1.1516, 1.7523, 0.8549],\n",
      "          [2.1089, 2.8923, 2.4825,  ..., 1.6442, 2.6577, 1.7223],\n",
      "          [2.3825, 2.9263, 2.2639,  ..., 1.7148, 2.3072, 1.7525],\n",
      "          ...,\n",
      "          [1.0201, 1.6269, 2.0990,  ..., 2.4829, 1.6345, 1.4359],\n",
      "          [1.5082, 1.7640, 1.9773,  ..., 2.3815, 1.8496, 1.2496],\n",
      "          [1.3849, 1.4571, 1.3029,  ..., 1.2074, 1.4423, 0.9923]],\n",
      "\n",
      "         [[1.5008, 2.0230, 1.6039,  ..., 1.4288, 2.2699, 0.9911],\n",
      "          [2.6296, 2.8769, 2.4344,  ..., 1.9238, 2.7313, 1.4096],\n",
      "          [2.3085, 2.8305, 2.4126,  ..., 2.0860, 2.2658, 1.6064],\n",
      "          ...,\n",
      "          [1.2658, 1.6130, 1.7257,  ..., 2.3082, 1.6137, 1.7015],\n",
      "          [1.9494, 1.8595, 1.8186,  ..., 2.1328, 2.2183, 1.3935],\n",
      "          [1.1052, 1.2074, 1.5438,  ..., 1.4085, 1.1869, 0.9627]],\n",
      "\n",
      "         [[1.2513, 1.7924, 1.5378,  ..., 1.4536, 1.8688, 1.2295],\n",
      "          [2.4129, 3.0451, 2.3795,  ..., 1.9702, 3.1526, 1.3482],\n",
      "          [2.6797, 2.9206, 2.6045,  ..., 1.8609, 2.8320, 1.2980],\n",
      "          ...,\n",
      "          [0.9336, 1.8742, 1.6901,  ..., 2.7117, 1.8222, 1.5972],\n",
      "          [1.7354, 2.0120, 1.8848,  ..., 2.4237, 1.6524, 2.0477],\n",
      "          [1.5351, 1.4823, 1.6245,  ..., 1.8707, 1.5952, 1.0273]],\n",
      "\n",
      "         [[1.2833, 1.8219, 1.6782,  ..., 1.3924, 1.6191, 1.2314],\n",
      "          [2.3143, 3.5412, 3.0860,  ..., 2.9601, 3.4016, 2.2998],\n",
      "          [2.5982, 3.5049, 3.3888,  ..., 1.7723, 2.7932, 2.1425],\n",
      "          ...,\n",
      "          [1.3385, 2.3291, 2.1872,  ..., 2.9442, 2.5913, 2.2526],\n",
      "          [1.6814, 2.0732, 2.4484,  ..., 2.9467, 2.1190, 2.3144],\n",
      "          [1.1835, 2.0310, 1.7039,  ..., 1.7734, 1.3054, 1.5705]],\n",
      "\n",
      "         [[0.8350, 1.0527, 0.7043,  ..., 0.7102, 1.0686, 0.5111],\n",
      "          [1.6876, 1.8504, 1.6910,  ..., 1.9194, 2.1757, 1.1749],\n",
      "          [1.6905, 2.1881, 1.8952,  ..., 1.2144, 1.5533, 1.1518],\n",
      "          ...,\n",
      "          [0.9804, 1.3724, 1.4290,  ..., 1.8080, 1.5376, 1.4228],\n",
      "          [1.2185, 1.0750, 1.1955,  ..., 1.6344, 1.6248, 1.0408],\n",
      "          [0.8392, 1.2373, 1.2751,  ..., 1.1540, 0.9322, 0.9356]]],\n",
      "\n",
      "\n",
      "        [[[0.5460, 0.2687, 0.9275,  ..., 1.1995, 0.7982, 1.0515],\n",
      "          [0.3432, 0.9700, 0.9660,  ..., 1.3669, 1.4429, 1.1106],\n",
      "          [0.4113, 1.2333, 0.6036,  ..., 0.8676, 1.4439, 1.3840],\n",
      "          ...,\n",
      "          [0.7604, 1.1870, 1.5063,  ..., 1.4515, 1.4930, 1.4026],\n",
      "          [0.4731, 1.6451, 0.7587,  ..., 1.2450, 1.5566, 0.7758],\n",
      "          [0.6375, 0.3512, 0.8983,  ..., 0.9833, 0.8855, 0.6477]],\n",
      "\n",
      "         [[0.5312, 1.0839, 1.3961,  ..., 1.4067, 1.9203, 1.4056],\n",
      "          [1.1915, 1.4392, 2.0581,  ..., 2.6731, 2.4074, 1.9371],\n",
      "          [1.3753, 1.8660, 1.4208,  ..., 2.5431, 3.0591, 1.9408],\n",
      "          ...,\n",
      "          [1.9305, 2.5906, 2.6806,  ..., 3.1925, 2.6994, 1.2868],\n",
      "          [1.6981, 2.4437, 2.2193,  ..., 2.3184, 2.8709, 1.7535],\n",
      "          [0.9437, 1.6693, 1.0838,  ..., 1.9034, 1.6397, 0.7146]],\n",
      "\n",
      "         [[0.7379, 1.5524, 1.6459,  ..., 1.6820, 2.5950, 1.3308],\n",
      "          [1.4797, 1.5074, 1.8289,  ..., 2.5208, 2.7651, 2.0996],\n",
      "          [1.3999, 1.4838, 1.2453,  ..., 2.6414, 2.9899, 2.0000],\n",
      "          ...,\n",
      "          [1.8406, 2.4699, 2.5648,  ..., 3.1222, 2.4802, 1.0806],\n",
      "          [1.5757, 2.2697, 2.4802,  ..., 2.8914, 2.7187, 1.7319],\n",
      "          [0.4983, 1.8056, 0.8903,  ..., 1.5251, 1.8623, 0.8867]],\n",
      "\n",
      "         [[0.7580, 1.2321, 1.5021,  ..., 1.6307, 2.1457, 1.3191],\n",
      "          [1.0526, 2.0387, 1.9204,  ..., 2.1418, 3.2120, 2.0788],\n",
      "          [1.6619, 1.4686, 1.6144,  ..., 2.7709, 2.8905, 2.3674],\n",
      "          ...,\n",
      "          [1.9861, 2.6050, 2.9441,  ..., 3.1349, 2.7999, 1.6942],\n",
      "          [1.7295, 2.3300, 2.6071,  ..., 3.1930, 2.7503, 1.2700],\n",
      "          [0.9553, 1.6783, 1.7330,  ..., 2.1730, 2.2661, 1.3972]],\n",
      "\n",
      "         [[0.8197, 1.2134, 1.4551,  ..., 1.7386, 2.2548, 1.6555],\n",
      "          [1.2732, 2.0807, 2.0608,  ..., 2.6136, 3.3556, 2.7261],\n",
      "          [1.3700, 2.0496, 2.0927,  ..., 3.1600, 3.4804, 3.2334],\n",
      "          ...,\n",
      "          [2.0770, 3.1975, 3.6040,  ..., 4.4205, 3.3759, 2.2799],\n",
      "          [1.7278, 3.2549, 3.0810,  ..., 3.1012, 3.5733, 2.2659],\n",
      "          [1.1969, 1.6333, 1.7207,  ..., 2.5401, 2.4772, 1.5244]],\n",
      "\n",
      "         [[0.3831, 0.8559, 0.7645,  ..., 0.8049, 1.4008, 0.6196],\n",
      "          [1.1046, 1.1276, 1.2348,  ..., 1.6535, 2.0464, 1.4665],\n",
      "          [0.9453, 1.0741, 1.3162,  ..., 2.0891, 2.3382, 1.7605],\n",
      "          ...,\n",
      "          [1.4711, 2.0838, 2.1600,  ..., 2.8192, 2.0826, 0.9793],\n",
      "          [1.2968, 1.8431, 2.1169,  ..., 1.8549, 1.9209, 1.4239],\n",
      "          [0.6260, 1.3910, 0.9152,  ..., 1.7427, 1.6379, 0.7397]]],\n",
      "\n",
      "\n",
      "        [[[0.1870, 0.5804, 0.3980,  ..., 0.9217, 1.0041, 0.5554],\n",
      "          [0.4356, 0.9012, 0.6666,  ..., 0.9734, 1.0314, 0.4653],\n",
      "          [0.8757, 1.0891, 1.2495,  ..., 0.7391, 0.9171, 0.5334],\n",
      "          ...,\n",
      "          [0.5013, 1.1543, 0.8816,  ..., 1.9954, 1.5783, 1.5624],\n",
      "          [0.3430, 0.8857, 0.9765,  ..., 1.4943, 1.1545, 0.9801],\n",
      "          [0.3269, 0.3297, 0.6708,  ..., 0.6198, 0.9511, 0.3536]],\n",
      "\n",
      "         [[0.5214, 0.6323, 0.7244,  ..., 1.4097, 1.6642, 0.6749],\n",
      "          [1.0899, 1.4106, 1.3927,  ..., 1.7534, 1.8734, 0.8348],\n",
      "          [1.4967, 1.8597, 2.4109,  ..., 1.6130, 1.5592, 0.6247],\n",
      "          ...,\n",
      "          [1.5940, 2.2637, 2.4474,  ..., 3.5674, 3.4843, 1.5174],\n",
      "          [0.9345, 1.7551, 1.9107,  ..., 2.7503, 2.4873, 1.7772],\n",
      "          [0.4160, 1.3037, 1.2029,  ..., 1.9246, 1.0384, 0.7170]],\n",
      "\n",
      "         [[0.6942, 0.5521, 1.1191,  ..., 1.6779, 1.7806, 0.6426],\n",
      "          [1.0970, 1.2151, 1.9875,  ..., 1.7993, 1.9275, 0.8612],\n",
      "          [1.9270, 2.0095, 2.2929,  ..., 1.5671, 1.4892, 0.5537],\n",
      "          ...,\n",
      "          [1.1968, 1.9820, 2.4714,  ..., 3.3911, 3.4259, 1.2470],\n",
      "          [0.7751, 1.9416, 1.9415,  ..., 3.1286, 2.4533, 1.5267],\n",
      "          [0.3084, 1.2293, 1.0871,  ..., 1.6545, 0.9417, 0.9672]],\n",
      "\n",
      "         [[0.7432, 0.6495, 0.7612,  ..., 1.6504, 1.5114, 0.7020],\n",
      "          [1.1866, 1.0074, 1.7871,  ..., 1.8883, 2.1937, 0.8172],\n",
      "          [1.7418, 1.9573, 2.3997,  ..., 1.6024, 1.9037, 0.7014],\n",
      "          ...,\n",
      "          [1.4040, 2.1923, 2.8097,  ..., 3.3547, 3.5999, 1.7957],\n",
      "          [0.8800, 1.7331, 2.3594,  ..., 3.0565, 3.3068, 1.0447],\n",
      "          [0.4050, 1.5666, 1.2861,  ..., 2.1284, 1.6083, 1.2106]],\n",
      "\n",
      "         [[0.4621, 0.6323, 1.0689,  ..., 1.7719, 1.6935, 0.8259],\n",
      "          [1.4634, 1.7495, 1.7012,  ..., 2.2474, 2.5379, 1.2161],\n",
      "          [2.1383, 2.2838, 2.2829,  ..., 2.3545, 2.3460, 1.0618],\n",
      "          ...,\n",
      "          [1.6677, 3.1549, 3.2550,  ..., 4.6009, 4.1596, 2.5328],\n",
      "          [1.1434, 2.0662, 2.7433,  ..., 3.6501, 3.7888, 2.1950],\n",
      "          [0.5414, 1.2298, 1.2650,  ..., 2.4293, 2.1545, 1.4808]],\n",
      "\n",
      "         [[0.3257, 0.1809, 0.6608,  ..., 0.8661, 0.8138, 0.2900],\n",
      "          [0.9067, 0.9200, 1.2434,  ..., 1.3734, 1.4415, 0.7171],\n",
      "          [1.2955, 1.1275, 1.3723,  ..., 1.6132, 1.3688, 0.5541],\n",
      "          ...,\n",
      "          [1.2480, 2.0527, 2.3295,  ..., 2.6563, 2.6341, 1.1282],\n",
      "          [0.7681, 1.3893, 1.6676,  ..., 2.3880, 2.2238, 1.3090],\n",
      "          [0.3040, 0.9414, 0.8672,  ..., 1.9201, 1.2606, 0.8878]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.5563, 0.6382, 1.0048,  ..., 1.0366, 1.4227, 0.7666],\n",
      "          [0.6101, 1.3486, 0.7098,  ..., 1.7313, 1.7973, 0.9759],\n",
      "          [0.9188, 0.7939, 1.1693,  ..., 1.6796, 1.4194, 1.2373],\n",
      "          ...,\n",
      "          [0.8233, 0.8585, 1.4643,  ..., 1.1791, 0.7251, 0.3880],\n",
      "          [0.7522, 0.9389, 1.2224,  ..., 0.7976, 1.1031, 0.7372],\n",
      "          [0.2776, 0.7190, 0.6030,  ..., 0.4034, 0.5601, 0.7215]],\n",
      "\n",
      "         [[0.9333, 1.3385, 1.4205,  ..., 2.2975, 1.8858, 1.3989],\n",
      "          [1.4729, 1.6708, 2.1881,  ..., 3.1467, 2.8845, 1.5273],\n",
      "          [1.8284, 1.9766, 1.8125,  ..., 3.1877, 2.9706, 1.4045],\n",
      "          ...,\n",
      "          [1.1237, 2.2976, 2.6711,  ..., 1.5227, 1.3701, 0.8064],\n",
      "          [1.5527, 1.5823, 2.4965,  ..., 2.0082, 1.6414, 1.2255],\n",
      "          [1.3712, 1.0465, 1.9985,  ..., 1.0154, 1.2451, 0.7696]],\n",
      "\n",
      "         [[1.4014, 1.4980, 1.4454,  ..., 3.0148, 2.0607, 1.4007],\n",
      "          [1.7271, 1.5067, 2.2182,  ..., 3.0592, 3.1413, 1.8250],\n",
      "          [1.6271, 2.3353, 1.8648,  ..., 2.9168, 2.9870, 1.3576],\n",
      "          ...,\n",
      "          [1.5300, 2.2760, 2.2378,  ..., 1.6301, 1.5511, 0.7673],\n",
      "          [1.7757, 1.8001, 2.8761,  ..., 1.9155, 2.0691, 1.3734],\n",
      "          [0.9551, 0.7825, 1.8413,  ..., 1.0067, 1.3467, 0.8495]],\n",
      "\n",
      "         [[1.1938, 1.3134, 1.4504,  ..., 2.5915, 1.9750, 1.1045],\n",
      "          [1.7441, 1.8958, 1.9886,  ..., 3.7047, 2.8544, 2.1983],\n",
      "          [1.7088, 2.0092, 2.4154,  ..., 3.0763, 3.1541, 1.8458],\n",
      "          ...,\n",
      "          [1.4532, 2.2238, 2.0620,  ..., 1.9095, 1.8922, 0.5197],\n",
      "          [1.5038, 2.4962, 2.4265,  ..., 1.5612, 2.1444, 1.4950],\n",
      "          [1.1039, 1.1759, 2.5252,  ..., 1.3329, 1.5086, 1.2318]],\n",
      "\n",
      "         [[1.3869, 1.4019, 1.1050,  ..., 2.4696, 2.4057, 1.5225],\n",
      "          [1.4775, 2.2987, 2.5893,  ..., 3.9562, 3.7256, 2.5620],\n",
      "          [2.3533, 2.8903, 2.2598,  ..., 3.9886, 3.7439, 2.4664],\n",
      "          ...,\n",
      "          [1.6988, 2.5554, 3.1928,  ..., 2.1660, 2.1265, 0.9211],\n",
      "          [1.6267, 2.4976, 2.5456,  ..., 2.3903, 2.9231, 1.8701],\n",
      "          [1.1761, 1.7971, 2.3588,  ..., 1.0737, 1.0912, 1.3395]],\n",
      "\n",
      "         [[0.8253, 0.7430, 0.5099,  ..., 1.5329, 1.0325, 0.6804],\n",
      "          [1.0639, 0.9950, 1.7721,  ..., 2.3247, 2.1584, 1.3053],\n",
      "          [1.5286, 1.9692, 1.2415,  ..., 2.3832, 2.4068, 1.2234],\n",
      "          ...,\n",
      "          [0.9244, 1.5369, 1.9246,  ..., 1.2365, 1.1680, 0.5266],\n",
      "          [1.2690, 1.3890, 1.6304,  ..., 1.7154, 1.7805, 0.9538],\n",
      "          [1.0493, 1.1470, 1.7216,  ..., 0.7357, 0.8041, 0.5885]]],\n",
      "\n",
      "\n",
      "        [[[0.7522, 0.9274, 1.3785,  ..., 1.1523, 1.1419, 1.1261],\n",
      "          [0.7490, 1.6775, 0.8162,  ..., 1.7610, 1.5901, 1.3258],\n",
      "          [0.7585, 1.5448, 1.1896,  ..., 1.6591, 2.0359, 1.3335],\n",
      "          ...,\n",
      "          [0.6399, 0.7762, 0.8774,  ..., 1.1166, 1.8935, 0.8582],\n",
      "          [0.3178, 1.0475, 1.1440,  ..., 1.9120, 1.1278, 1.2972],\n",
      "          [0.3142, 0.4791, 0.7306,  ..., 0.7350, 0.7841, 0.7057]],\n",
      "\n",
      "         [[1.1547, 2.0622, 1.7995,  ..., 1.9744, 2.1351, 1.0962],\n",
      "          [1.6805, 2.5113, 2.6218,  ..., 2.8527, 3.3210, 2.0785],\n",
      "          [2.0199, 2.8418, 1.9812,  ..., 3.3719, 3.4273, 2.2989],\n",
      "          ...,\n",
      "          [1.2557, 1.8168, 1.3532,  ..., 2.9862, 2.8514, 2.0700],\n",
      "          [1.0599, 2.1781, 2.1575,  ..., 2.9529, 2.8658, 1.5009],\n",
      "          [0.4321, 1.4004, 1.3577,  ..., 1.8249, 1.8754, 1.0995]],\n",
      "\n",
      "         [[1.6816, 2.4387, 1.8786,  ..., 2.3061, 2.4500, 0.9793],\n",
      "          [1.8748, 2.4476, 2.5946,  ..., 3.4579, 3.2575, 1.7897],\n",
      "          [1.6750, 2.9133, 2.2642,  ..., 3.6529, 3.7324, 2.3968],\n",
      "          ...,\n",
      "          [0.8574, 2.2570, 1.6976,  ..., 3.0686, 2.4805, 2.2761],\n",
      "          [1.0630, 2.2219, 2.0874,  ..., 2.6499, 3.1406, 1.6215],\n",
      "          [0.4761, 1.3281, 1.2404,  ..., 1.8617, 1.6095, 1.0298]],\n",
      "\n",
      "         [[1.5288, 2.0713, 1.9714,  ..., 1.9203, 2.1197, 1.2913],\n",
      "          [1.8779, 2.9915, 2.3835,  ..., 3.4735, 3.5543, 1.4149],\n",
      "          [1.8418, 2.7172, 2.7882,  ..., 3.7913, 4.0362, 2.3240],\n",
      "          ...,\n",
      "          [1.1434, 2.1321, 2.1892,  ..., 2.8064, 2.8318, 1.9856],\n",
      "          [0.7182, 2.4987, 2.0912,  ..., 3.4815, 2.5168, 2.2940],\n",
      "          [0.6436, 1.6935, 1.3690,  ..., 2.0929, 2.4191, 1.0449]],\n",
      "\n",
      "         [[1.7371, 2.0366, 1.7158,  ..., 2.4338, 1.9395, 1.4225],\n",
      "          [1.7108, 3.3950, 3.0608,  ..., 3.9339, 3.9188, 2.5479],\n",
      "          [2.5240, 3.6440, 3.1494,  ..., 4.3831, 4.9004, 3.2447],\n",
      "          ...,\n",
      "          [1.4262, 2.3343, 2.0685,  ..., 2.9717, 3.7133, 3.0620],\n",
      "          [1.4332, 2.8797, 2.8653,  ..., 3.9545, 3.0550, 2.7475],\n",
      "          [0.3381, 1.1423, 1.4863,  ..., 2.5731, 2.3583, 1.7821]],\n",
      "\n",
      "         [[0.9774, 1.1865, 0.7432,  ..., 1.2233, 1.1035, 0.4051],\n",
      "          [1.2393, 1.7572, 2.1285,  ..., 2.2419, 2.2212, 1.3752],\n",
      "          [1.7021, 2.3186, 1.8887,  ..., 2.8941, 2.8416, 1.7467],\n",
      "          ...,\n",
      "          [0.9327, 1.6896, 1.1661,  ..., 1.9470, 2.0463, 1.9753],\n",
      "          [1.1100, 1.8751, 1.7910,  ..., 2.0012, 2.1915, 1.3286],\n",
      "          [0.1862, 0.8055, 0.9433,  ..., 1.7657, 1.5869, 1.1367]]],\n",
      "\n",
      "\n",
      "        [[[0.2382, 0.9980, 0.8328,  ..., 1.3613, 0.9930, 0.5644],\n",
      "          [0.5224, 1.1422, 1.9551,  ..., 1.0710, 1.3412, 1.2193],\n",
      "          [0.8859, 1.6271, 0.9690,  ..., 1.1882, 1.6495, 0.9787],\n",
      "          ...,\n",
      "          [0.6424, 0.8251, 1.7374,  ..., 1.5797, 2.0767, 1.0512],\n",
      "          [0.7556, 1.7513, 1.5018,  ..., 1.4354, 1.5085, 1.6741],\n",
      "          [0.8035, 1.0137, 0.9418,  ..., 1.0986, 1.1139, 0.4478]],\n",
      "\n",
      "         [[0.7659, 1.2314, 2.3220,  ..., 1.8931, 1.6566, 0.9416],\n",
      "          [1.8587, 2.5739, 2.6809,  ..., 2.8473, 2.8396, 1.5885],\n",
      "          [1.8114, 2.7790, 2.6071,  ..., 1.9906, 2.5171, 1.6577],\n",
      "          ...,\n",
      "          [1.3225, 2.4939, 2.5714,  ..., 3.2375, 3.2147, 1.7580],\n",
      "          [1.8464, 3.0337, 3.3812,  ..., 2.9611, 3.8293, 1.8748],\n",
      "          [1.6625, 2.0895, 1.8352,  ..., 1.6870, 2.0263, 1.2611]],\n",
      "\n",
      "         [[1.0651, 1.6990, 3.1618,  ..., 1.9093, 1.9297, 1.1228],\n",
      "          [1.8823, 2.3679, 2.3110,  ..., 2.8968, 2.7053, 1.4052],\n",
      "          [2.3023, 2.2150, 2.2269,  ..., 2.5958, 2.8075, 1.7302],\n",
      "          ...,\n",
      "          [1.2996, 2.5416, 2.6154,  ..., 3.0017, 3.2418, 2.0517],\n",
      "          [2.4497, 2.9791, 2.9894,  ..., 3.2468, 3.6798, 1.5551],\n",
      "          [1.3873, 2.1184, 1.6830,  ..., 1.7376, 1.8297, 1.2792]],\n",
      "\n",
      "         [[1.0642, 1.7063, 2.6372,  ..., 2.1337, 1.9996, 1.1713],\n",
      "          [1.8572, 2.1708, 3.3400,  ..., 2.6511, 2.7845, 1.6244],\n",
      "          [2.4323, 2.5032, 1.9551,  ..., 2.9677, 2.9400, 1.5752],\n",
      "          ...,\n",
      "          [1.4550, 2.2420, 3.0497,  ..., 3.1391, 3.4840, 2.3379],\n",
      "          [2.0273, 3.3267, 2.8269,  ..., 3.4027, 3.5847, 1.9226],\n",
      "          [1.8976, 2.4418, 2.2993,  ..., 2.3725, 2.9246, 0.8589]],\n",
      "\n",
      "         [[0.3545, 1.6743, 2.5107,  ..., 1.6866, 1.5634, 1.2221],\n",
      "          [2.2625, 2.5724, 3.5256,  ..., 4.0055, 4.0830, 2.6377],\n",
      "          [1.9905, 3.2211, 2.9415,  ..., 2.8260, 2.9990, 2.0123],\n",
      "          ...,\n",
      "          [1.7201, 2.5138, 3.3083,  ..., 3.7141, 3.9879, 2.8880],\n",
      "          [2.2118, 3.8871, 3.6253,  ..., 4.2532, 4.2640, 2.9794],\n",
      "          [1.4471, 2.4230, 2.6184,  ..., 2.4564, 2.9620, 1.6781]],\n",
      "\n",
      "         [[0.4075, 0.8681, 1.6580,  ..., 0.6984, 0.8002, 0.5578],\n",
      "          [1.5936, 1.7672, 1.8465,  ..., 2.6970, 2.6222, 1.4435],\n",
      "          [1.2492, 1.5675, 2.0160,  ..., 1.7560, 1.5135, 0.9596],\n",
      "          ...,\n",
      "          [1.0444, 1.8426, 1.8937,  ..., 2.2585, 2.3115, 1.6141],\n",
      "          [1.6004, 2.1101, 2.2747,  ..., 2.5687, 2.7945, 1.4865],\n",
      "          [0.9901, 1.5789, 1.5367,  ..., 1.6504, 1.6779, 1.2066]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "image = torch.rand(10,1,28,28)\n",
    "\n",
    "filters = torch.rand(6,1,3,3)\n",
    "\n",
    "output_feature = F.conv2d(image, filters, stride =1, padding = 1)\n",
    "print(output_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[6., 9.],\n",
      "          [3., 4.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "\n",
    "im = torch.Tensor([[[[3,1,3,5],[6,0,7,9],[3,2,1,4],[0,2,4,3]]]])\n",
    "\n",
    "max_pooling = torch.nn.MaxPool2d(2)\n",
    "output_feature = max_pooling(im)\n",
    "print(output_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[2.5000, 6.0000],\n",
      "          [1.7500, 3.0000]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "\n",
    "im = torch.Tensor([[[[3,1,3,5],[6,0,7,9],[3,2,1,4],[0,2,4,3]]]])\n",
    "\n",
    "max_pooling = torch.nn.AvgPool2d(2)\n",
    "output_feature = max_pooling(im)\n",
    "print(output_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
