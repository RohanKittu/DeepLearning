{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from [here](https://www.analyticsvidhya.com/blog/2019/09/introduction-to-pytorch-from-scratch/) and form [here](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch tensors are multidimensinal arrays.\n",
    "- FloatTensor: 32-bit float\n",
    "- DoubleTensor: 64-bit float\n",
    "- HalfTensor: 16-bit float\n",
    "- IntTensor: 32-bit int\n",
    "- LongTensor: 64-bit int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "#initialize an array\n",
    "a = torch.tensor(1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check type\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Math operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2) tensor(5)\n"
     ]
    }
   ],
   "source": [
    "#intialize tensor\n",
    "a = torch.tensor(2)\n",
    "b = torch.tensor(5)\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n",
      "tensor(-3)\n",
      "tensor(10)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "#addition\n",
    "print(a+b)\n",
    "print(a-b)\n",
    "print(a*b)\n",
    "print(a/b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Matrix intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "#matrix\n",
    "a = torch.zeros((3,3))\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((3,3))\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3367,  0.1288,  0.2345],\n",
       "        [ 0.2303, -1.1229, -0.1863],\n",
       "        [ 2.2082, -0.6380,  0.4617]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.randn(3,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "#zero matrix with \"Long\" dtype\n",
    "x = torch.zeros(5,3, dtype = torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.5000, 3.0000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#construct a tensor directly from data\n",
    "x = torch.tensor([5.5,3])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4,. Matrix operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.randn(3,3)\n",
    "b = torch.randn(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6040,  0.6637,  1.0438],\n",
      "        [ 1.3406, -2.8127, -1.1753],\n",
      "        [ 3.1662,  0.6841,  1.2788]]) \n",
      "\n",
      "tensor([[ 0.0693, -0.4061, -0.5749],\n",
      "        [-0.8800,  0.5669,  0.8026],\n",
      "        [ 1.2502, -1.9601, -0.3555]]) \n",
      "\n",
      "tensor([[ 0.4576,  0.2724,  0.3367],\n",
      "        [-1.3636,  1.7743,  1.1446],\n",
      "        [ 0.3243,  2.8696,  2.7954]]) \n",
      "\n",
      "tensor([[ 1.2594,  0.2408,  0.2897],\n",
      "        [ 0.2075,  0.6645,  0.1884],\n",
      "        [ 2.3051, -0.4826,  0.5649]])\n"
     ]
    }
   ],
   "source": [
    "#matrix addition\n",
    "print(torch.add(a,b),'\\n')\n",
    "\n",
    "#matrix subtraction\n",
    "print(torch.sub(a,b),'\\n')\n",
    "\n",
    "#matrix multiplication\n",
    "print(torch.mm(a,b), '\\n')\n",
    "\n",
    "#matrix division\n",
    "print(torch.div(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.mm() is similar to dot product in numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3367,  0.2303,  2.2082],\n",
       "        [ 0.1288, -1.1229, -0.6380],\n",
       "        [ 0.2345, -0.1863,  0.4617]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matrix transpose\n",
    "torch.t(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3367,  0.1288,  0.2345],\n",
       "        [ 0.2303, -1.1229, -0.1863],\n",
       "        [ 2.2082, -0.6380,  0.4617],\n",
       "        [ 0.2674,  0.5349,  0.8094],\n",
       "        [ 1.1103, -1.6898, -0.9890],\n",
       "        [ 0.9580,  1.3221,  0.8172]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matrix concating vertically\n",
    "torch.cat((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3367,  0.1288,  0.2345,  0.2674,  0.5349,  0.8094],\n",
       "        [ 0.2303, -1.1229, -0.1863,  1.1103, -1.6898, -0.9890],\n",
       "        [ 2.2082, -0.6380,  0.4617,  0.9580,  1.3221,  0.8172]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matrix concating horizontally\n",
    "torch.cat((a,b), dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. reshape tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229, -0.1863,  2.2082, -0.6380,\n",
      "          0.4617]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape\n",
    "c = a.reshape(1,9)\n",
    "print(c)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Numpy Array to pytorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]] \n",
      "\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[1,2],[3,4]])\n",
    "print(a,'\\n')\n",
    "\n",
    "#convert numpy to tensor\n",
    "tensor = torch.from_numpy(a)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Common pytorch modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1. Autograd Module\n",
    "- Pytorch has Autograd Module that records all the operations that we perform and replays backward to compute gradients.\n",
    "- This helps us to save time on each epoch to calculate gradient on the forward pass itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =torch.ones((2,2), requires_grad = True)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`requires_grad = True` makes sure that gradients are stored, when ever we make some operations on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 6.],\n",
      "        [6., 6.]], grad_fn=<AddBackward0>) tensor(6., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "b = a+5\n",
    "c = b.mean()\n",
    "print(b,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we first added `5` to all the elements of a tensor, and then taken `mean` of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$b = a+5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$c= mean(b) = summation(a+5)/4$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now the derivative of `C` w.r.t `a` will be 1/4 and hence the `Gradient matrix` will be 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2500, 0.2500],\n",
      "        [0.2500, 0.2500]])\n"
     ]
    }
   ],
   "source": [
    "#backpropogate\n",
    "c.backward()\n",
    "\n",
    "#computing grad\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The autograd module helps us to compute the gradients in the forward pass itself which saves a lot of computation time of an epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Optim Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it has optimizers that are used while building Neural Networks.\n",
    "- SGD\n",
    "- Adam\n",
    "- Adadelta\n",
    "- Adagrad\n",
    "- AdamW\n",
    "- SparseAdam\n",
    "- Adamax\n",
    "- ASGD (Averaged Stochastic Gradient Descent)\n",
    "- RMSprop\n",
    "- Rprop (resilient backpropagation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import optim module\n",
    "from torch import optim\n",
    "\n",
    "#adam\n",
    "#adam = optim.Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "# sgd\n",
    "## SGD = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([[1,2,3],[3,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnesor = tensor.view((1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 3, 4, 5]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnesor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
