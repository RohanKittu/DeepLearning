{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Packages and Description\n",
    "- torch -> Main Tensor Library\n",
    "- torch.nn ->  A Subpackage that contains modules and extensible classes for building neural network.\n",
    "- torch.autograd -> A subpackage that supports all **differentiable tensor operation** in pytorch.\n",
    "- torch.nn.functional ->it has **Loss Functions, Activation functions, and Convolution operation**.\n",
    "- torch.optim -> contains SGD, ADAM and More.\n",
    "- torch.utils -> contains utility clasess to load **datasets,dataloaders**.\n",
    "- torchvision -> for **datasets, model architecture** and more.\n",
    "- torchvision.transforms -> to transform/preprocess your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **index**(0), in **Computer science** its *Number*, in **Mathematics** its *Scalar*.\n",
    "- **index**(1), in **Computer science** its *Array*, in **Mathematics** its *Vector*.\n",
    "- **index**(2), in **Computer science** its *2d-array*, in **Mathematics** its *matrix*.\n",
    "- **index**(n, in **Computer science** its *nd-array*, in **Mathematics** its *nd-tensor*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### moving code to GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here index 0 is saying move all your code to first gpu. If you say 'cuda:3', then you should have 4 gpus with you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### case-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "t1 = torch.tensor([1,2,3])\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.tensor([1.,2.,3.])\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4., 6.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding t1,t2 throws Error\n",
    "t1+t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#note the diff here\n",
    "import numpy as np\n",
    "data = np.array([1,2,3])\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in both the above cells Notice that, **Tensor** returned **floats**, while **tensor** returned **ints**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### few oprations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7758, 0.0136],\n",
       "        [0.9725, 0.8905]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[1,1,1,1],\n",
    "                [2,2,2,2],\n",
    "                [3,3,3,3]], dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to know number of elements\n",
    "t.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 2., 2.],\n",
       "        [2., 2., 3.],\n",
       "        [3., 3., 3.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape\n",
    "t.reshape(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [3.],\n",
       "        [3.],\n",
       "        [3.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape\n",
    "t.reshape(12,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 3.],\n",
       "         [3., 3., 3.]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape\n",
    "t.reshape(2,2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeeze and Unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])\n",
      "torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "#original\n",
    "print(t.reshape(1,12))\n",
    "print(t.reshape(1,12).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.])\n",
      "torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "#squeezed or flatten to rank1 tensor which mean only 1 axis\n",
    "print(t.reshape(1,12).squeeze())\n",
    "print(t.reshape(1,-1).squeeze().shape)\n",
    "#look here, we replace 12 with -1, which means automatically \n",
    "#calculates the size of t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 2., 2., 2., 2., 3., 3., 3., 3.]])\n",
      "torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "#unsqueezed\n",
    "print(t.reshape(1,12).squeeze().unsqueeze(dim=0))\n",
    "print(t.reshape(1,12).squeeze().unsqueeze(dim=0).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.tensor([[1,2],\n",
    "                  [3,4]])\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 6],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.tensor([[5,6],\n",
    "                  [7,8]])\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concat row wise\n",
    "torch.cat((t1,t2),dim =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 5, 6],\n",
       "        [3, 4, 7, 8]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concat column wise\n",
    "torch.cat((t1,t2),dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Flatten visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.rand(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2  = torch.rand(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = torch.rand(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 4])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now stack them up\n",
    "t = torch.stack((t1,t2,t3))\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9869, 0.7053, 0.9614, 0.5747],\n",
       "         [0.4070, 0.6991, 0.1532, 0.9386],\n",
       "         [0.4735, 0.7032, 0.3851, 0.7180],\n",
       "         [0.2052, 0.3957, 0.5808, 0.1698]],\n",
       "\n",
       "        [[0.8906, 0.0961, 0.1576, 0.6826],\n",
       "         [0.1933, 0.8078, 0.6731, 0.6201],\n",
       "         [0.1704, 0.7303, 0.4715, 0.4375],\n",
       "         [0.7565, 0.5594, 0.1796, 0.2615]],\n",
       "\n",
       "        [[0.1866, 0.6286, 0.4785, 0.9504],\n",
       "         [0.1650, 0.6815, 0.6451, 0.0425],\n",
       "         [0.3692, 0.0742, 0.7326, 0.7904],\n",
       "         [0.2136, 0.1404, 0.9761, 0.9162]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As CNN's also consider Color channel in its inputs, lets add color channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t.reshape(3,1,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9869, 0.7053, 0.9614, 0.5747],\n",
       "          [0.4070, 0.6991, 0.1532, 0.9386],\n",
       "          [0.4735, 0.7032, 0.3851, 0.7180],\n",
       "          [0.2052, 0.3957, 0.5808, 0.1698]]],\n",
       "\n",
       "\n",
       "        [[[0.8906, 0.0961, 0.1576, 0.6826],\n",
       "          [0.1933, 0.8078, 0.6731, 0.6201],\n",
       "          [0.1704, 0.7303, 0.4715, 0.4375],\n",
       "          [0.7565, 0.5594, 0.1796, 0.2615]]],\n",
       "\n",
       "\n",
       "        [[[0.1866, 0.6286, 0.4785, 0.9504],\n",
       "          [0.1650, 0.6815, 0.6451, 0.0425],\n",
       "          [0.3692, 0.0742, 0.7326, 0.7904],\n",
       "          [0.2136, 0.1404, 0.9761, 0.9162]]]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9869, 0.7053, 0.9614, 0.5747, 0.4070, 0.6991, 0.1532, 0.9386, 0.4735,\n",
       "         0.7032, 0.3851, 0.7180, 0.2052, 0.3957, 0.5808, 0.1698, 0.8906, 0.0961,\n",
       "         0.1576, 0.6826, 0.1933, 0.8078, 0.6731, 0.6201, 0.1704, 0.7303, 0.4715,\n",
       "         0.4375, 0.7565, 0.5594, 0.1796, 0.2615, 0.1866, 0.6286, 0.4785, 0.9504,\n",
       "         0.1650, 0.6815, 0.6451, 0.0425, 0.3692, 0.0742, 0.7326, 0.7904, 0.2136,\n",
       "         0.1404, 0.9761, 0.9162]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now flatten\n",
    "t.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9869, 0.7053, 0.9614, 0.5747, 0.4070, 0.6991, 0.1532, 0.9386, 0.4735,\n",
       "        0.7032, 0.3851, 0.7180, 0.2052, 0.3957, 0.5808, 0.1698, 0.8906, 0.0961,\n",
       "        0.1576, 0.6826, 0.1933, 0.8078, 0.6731, 0.6201, 0.1704, 0.7303, 0.4715,\n",
       "        0.4375, 0.7565, 0.5594, 0.1796, 0.2615, 0.1866, 0.6286, 0.4785, 0.9504,\n",
       "        0.1650, 0.6815, 0.6451, 0.0425, 0.3692, 0.0742, 0.7326, 0.7904, 0.2136,\n",
       "        0.1404, 0.9761, 0.9162])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatten way2\n",
    "t.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9869, 0.7053, 0.9614, 0.5747, 0.4070, 0.6991, 0.1532, 0.9386, 0.4735,\n",
       "        0.7032, 0.3851, 0.7180, 0.2052, 0.3957, 0.5808, 0.1698, 0.8906, 0.0961,\n",
       "        0.1576, 0.6826, 0.1933, 0.8078, 0.6731, 0.6201, 0.1704, 0.7303, 0.4715,\n",
       "        0.4375, 0.7565, 0.5594, 0.1796, 0.2615, 0.1866, 0.6286, 0.4785, 0.9504,\n",
       "        0.1650, 0.6815, 0.6451, 0.0425, 0.3692, 0.0742, 0.7326, 0.7904, 0.2136,\n",
       "        0.1404, 0.9761, 0.9162])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatten way3\n",
    "t.view(t.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9869, 0.7053, 0.9614, 0.5747, 0.4070, 0.6991, 0.1532, 0.9386, 0.4735,\n",
       "        0.7032, 0.3851, 0.7180, 0.2052, 0.3957, 0.5808, 0.1698, 0.8906, 0.0961,\n",
       "        0.1576, 0.6826, 0.1933, 0.8078, 0.6731, 0.6201, 0.1704, 0.7303, 0.4715,\n",
       "        0.4375, 0.7565, 0.5594, 0.1796, 0.2615, 0.1866, 0.6286, 0.4785, 0.9504,\n",
       "        0.1650, 0.6815, 0.6451, 0.0425, 0.3692, 0.0742, 0.7326, 0.7904, 0.2136,\n",
       "        0.1404, 0.9761, 0.9162])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tutorial [here](https://www.youtube.com/watch?v=stWU37L91Yc&t=739s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,5)\n",
    "        self.conv2 = nn.Conv2d(6,12,5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(12*4*4,120)\n",
    "        self.fc2 = nn.Linear(120,60)\n",
    "        self.out = nn.Linear(60,10)\n",
    "        \n",
    "    def forward(x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noteice here that thought we gavve kernel size is just 5, internally it is like a tuple of (5,5) representing the shape of filter. Also notice here that stride is (1,1), though we didnt give anything in code. By default stride is 1. and in (1,1), first one is for moving 1 stride left, other 1 for moving 1 down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "print(network.conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "print(network.conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=192, out_features=120, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(network.fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=120, out_features=60, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(network.fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=60, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(network.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.0571,  0.0678,  0.0539, -0.0469, -0.1322],\n",
      "          [ 0.1886, -0.1164,  0.0810, -0.0857, -0.0408],\n",
      "          [-0.0064, -0.0271,  0.0505,  0.0172, -0.1112],\n",
      "          [ 0.1092,  0.1348,  0.0199, -0.0546,  0.0686],\n",
      "          [ 0.1281,  0.1110, -0.0227,  0.1108,  0.1952]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0372, -0.0004,  0.0626,  0.1974, -0.0649],\n",
      "          [ 0.0471, -0.0841,  0.0950,  0.0936,  0.1080],\n",
      "          [-0.1308, -0.1270,  0.1296, -0.1837,  0.1346],\n",
      "          [-0.1614,  0.1111,  0.0014,  0.1656, -0.0430],\n",
      "          [-0.0921,  0.0779,  0.1964,  0.1505,  0.1319]]],\n",
      "\n",
      "\n",
      "        [[[-0.1364,  0.1240, -0.0711,  0.1910,  0.1127],\n",
      "          [-0.0152,  0.0606,  0.1458, -0.1553,  0.0575],\n",
      "          [ 0.1572,  0.1410,  0.0063, -0.1345,  0.1978],\n",
      "          [-0.0341, -0.1867, -0.1984,  0.0488,  0.0355],\n",
      "          [ 0.1386,  0.1060, -0.0771, -0.0254,  0.0363]]],\n",
      "\n",
      "\n",
      "        [[[-0.0991,  0.1674,  0.0653,  0.1194,  0.0218],\n",
      "          [ 0.1741,  0.0187, -0.1611, -0.0637,  0.1997],\n",
      "          [-0.1218,  0.1925, -0.0939, -0.0687,  0.1565],\n",
      "          [-0.1055,  0.0188, -0.1915,  0.0091, -0.0383],\n",
      "          [-0.0028,  0.1306,  0.0488,  0.1931,  0.0765]]],\n",
      "\n",
      "\n",
      "        [[[-0.0966, -0.1775,  0.0215,  0.1999,  0.0736],\n",
      "          [-0.1943,  0.1608, -0.1252,  0.1907, -0.1487],\n",
      "          [ 0.1242, -0.0003,  0.1736,  0.0164,  0.1091],\n",
      "          [ 0.0828, -0.0787,  0.0394, -0.1409, -0.0775],\n",
      "          [ 0.1560,  0.1907,  0.1328,  0.0702,  0.0658]]],\n",
      "\n",
      "\n",
      "        [[[-0.0882, -0.0025,  0.1005,  0.1759, -0.0616],\n",
      "          [-0.1576,  0.0559, -0.0656, -0.0239, -0.1219],\n",
      "          [ 0.0390,  0.1553, -0.1776,  0.1530, -0.0851],\n",
      "          [-0.1782,  0.0411,  0.0233, -0.1102,  0.1507],\n",
      "          [-0.1908,  0.0250, -0.0128,  0.1959, -0.1837]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(network.conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(network.conv1.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above parameters/weights are learned as we train the Network in such a way that the loss function is minimized.\n",
    "\n",
    "The parameter class keeps track of all the weights in network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 6, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "#self.conv2  = nn.Conv2d(6,12,5)\n",
    "print(network.conv2.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 192])\n"
     ]
    }
   ],
   "source": [
    "print(network.fc1.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 120])\n"
     ]
    }
   ],
   "source": [
    "print(network.fc2.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 60])\n"
     ]
    }
   ],
   "source": [
    "print(network.out.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Network(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(network.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([12, 6, 5, 5])\n",
      "torch.Size([12])\n",
      "torch.Size([120, 192])\n",
      "torch.Size([120])\n",
      "torch.Size([60, 120])\n",
      "torch.Size([60])\n",
      "torch.Size([10, 60])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for param in network.parameters():\n",
    "    print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight \t\t torch.Size([6, 1, 5, 5])\n",
      "conv1.bias \t\t torch.Size([6])\n",
      "conv2.weight \t\t torch.Size([12, 6, 5, 5])\n",
      "conv2.bias \t\t torch.Size([12])\n",
      "fc1.weight \t\t torch.Size([120, 192])\n",
      "fc1.bias \t\t torch.Size([120])\n",
      "fc2.weight \t\t torch.Size([60, 120])\n",
      "fc2.bias \t\t torch.Size([60])\n",
      "out.weight \t\t torch.Size([10, 60])\n",
      "out.bias \t\t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, param in network.named_parameters():\n",
    "    print(name,  '\\t\\t', param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward operation \n",
    "-- from [here](https://www.youtube.com/watch?v=MasG7tZj-hw&list=PLZbbT5o_s2xrfNyHZsM6ufI0iZENK9xgG&index=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,5)\n",
    "        self.conv2 = nn.Conv2d(6,12,5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(12*4*4,120)\n",
    "        self.fc2 = nn.Linear(120,60)\n",
    "        self.out = nn.Linear(60,10)\n",
    "        \n",
    "    def forward(x):\n",
    "        #(1) input layer\n",
    "        x=x\n",
    "        \n",
    "        #(2) hidden conv layer\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,kernel_size = 2,stride = 2)\n",
    "        \n",
    "        #(3) hidden conv layer\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,kernel_size = 2,stride = 2)\n",
    "        \n",
    "        #(4)hidden linear layer\n",
    "        x = x.reshape(-1,12*4*4)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        #(5)hidden Linear layer\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        #(6)output layer\n",
    "        x = self.out(x)\n",
    "        #x = F.softmax(x,dim=1)\n",
    "        '''We are not using softmax here, because of the loss function. CrossEntropyLoss function implicitly performs softmax operation'''\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the relu and max pool are just pure operations and neither of them has weights, hence we call them from **functional** with F\n",
    "\n",
    "and also remember that convolution1 is a combination of Convolution layer and 3 operations named convolution, relu, maxpool -- from [here](https://www.youtube.com/watch?v=MasG7tZj-hw&list=PLZbbT5o_s2xrfNyHZsM6ufI0iZENK9xgG&index=21)\n",
    "\n",
    "with all hidden layer, people often use **ReLU**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Hyper parameter training in Deep learning](https://www.youtube.com/watch?v=ycxulUVoNbk&list=PLZbbT5o_s2xrfNyHZsM6ufI0iZENK9xgG&index=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### you should always apply ReLU first and then Max-Pool later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from [here](https://discuss.pytorch.org/t/example-on-how-to-use-batch-norm/216), observe the below one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_bn = nn.BatchNorm2d(20)\n",
    "        self.dense1 = nn.Linear(in_features=320, out_features=50)\n",
    "        self.dense1_bn = nn.BatchNorm1d(50)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Value inside **Batch Normalization** realted to the **outputsize of Conv** layers. \n",
    "\n",
    "- And also notice that for **Conv** Layer its **BatchNorm2d** and for **Linear** layer its **BatchNorm1d**.\n",
    "\n",
    "- BatchNorm will only update the running averages in train mode, so if you want the model to keep updating them in test time, you will have to keep BatchNorm modules in the training mode. See the C implementation 670 for details (it should be readable).-- from [here](https://discuss.pytorch.org/t/example-on-how-to-use-batch-norm/216/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
